{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import rc_tools as rct\n",
    "import rc_analysis as rca\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.signal import argrelextrema\n",
    "import sys\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "import pdb\n",
    "\n",
    "from skopt.space import Real,Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "\n",
    "from scipy.integrate import odeint\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import warnings\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='solarizedd', context='notebook', ticks=True, grid=False)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(11)\n",
    "torch.set_printoptions(precision=10)\n",
    "dtype = torch.float32 \n",
    "\n",
    "print(f'Python: {sys.version}')\n",
    "print(f'Numpy: {np.__version__}')\n",
    "print(f'Torch: {torch.__version__}')\n",
    "\n",
    "FREERUN = 20  # Extra predicition time-steps after test data\n",
    "deltaT = .02      # Number of extra free-running steps  int(20/.02) \n",
    "\n",
    "rho = 28.0\n",
    "sigma = 10.0\n",
    "beta = 8/3\n",
    "\n",
    "# Lorenz 1963\n",
    "def f(state, t):\n",
    "    x,y,z = state\n",
    "    return sigma*(y-x), x*(rho-z)-y, x*y - beta*z\n",
    "\n",
    "state0 = [1.,1.,1.]             # Initial point\n",
    "t = np.arange(0,300+FREERUN,deltaT)  # Total of 320 full steps with deltaT=.02\n",
    "states = odeint(f,state0,t)\n",
    "\n",
    "mu = np.mean(states, axis=0)       # Get mean for each of x,y,z\n",
    "signal = (states - mu)[:,[0,1,2]]  # Mean center the data\n",
    "M = signal.shape[0] - int(FREERUN/deltaT)  # Length of train plus test... no freerun\n",
    "#N = 25                                 # Reservoir matrix size\n",
    "K = 3                                  # Input dimension\n",
    "L = 3                                  # Output dimension\n",
    "RF = .5                                # For feedback <--- not implemented\n",
    "TEST = 1000                            # length of test\n",
    "LEAD = 100                            # Number of points to plot before test\n",
    "BURNIN = 100                           # Number of steps ignored for random x0 to fade\n",
    "REG = 1e-8                             # Regularization factor for ridge regression\n",
    "TRAINLENGTH = M-TEST    \n",
    "\n",
    "MINMAXS = np.max(signal[:TRAINLENGTH+TEST],axis=0)-np.min(signal[:TRAINLENGTH+TEST],axis=0)\n",
    "RGS = [(-19.5,19.5),(-27,27),(-25,25)]\n",
    "BINS = 50\n",
    "\n",
    "print(f'Signal length M={M}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_matricesGPU(k,n,l,ri,ro):\n",
    "    #pdb.set_trace()\n",
    "    win = torch.rand((n,k),dtype=dtype,\n",
    "                      device=torch.device('cuda')).sub(.5).mul(ri)\n",
    "    wfb = torch.zeros((n,l),dtype=dtype, device=torch.device('cuda'))\n",
    "    wout = torch.rand((l,n+k),dtype=dtype,\n",
    "                      device=torch.device('cuda')).sub(.5).mul(ro)\n",
    "    return win, wfb, wout\n",
    "\n",
    "def set_vectorsGPU(n,l,r):\n",
    "    #pdb.set_trace\n",
    "    x0 = torch.rand((n,1),dtype=dtype,\n",
    "                      device=torch.device('cuda')).sub(.5).mul(r)\n",
    "    y0 = torch.zeros((l,1),dtype=dtype, device=torch.device('cuda'))\n",
    "    return x0, y0\n",
    "\n",
    "def update_res_stateGPU(wnet,xt,uxy,a,g):\n",
    "    z = torch.matmul(wnet,uxy)\n",
    "    return torch.mul(xt,1-a) + torch.mul(torch.tanh(z),a*g)\n",
    "\n",
    "def predict_yGPU(wout,xu):\n",
    "    return torch.matmul(wout, xu)\n",
    "\n",
    "def get_matrixGPU(n,r,sr):\n",
    "    #pdb.set_trace()\n",
    "    A = (torch.rand((n,n),dtype=dtype,\n",
    "                   device=torch.device('cuda'))-.5)*r\n",
    "    At = torch.transpose(A,0,1)\n",
    "    D = torch.diag(torch.diag(A))   \n",
    "    W = A + At - D\n",
    "    eig = torch.eig(W, eigenvectors=False)\n",
    "    wsr = torch.max(torch.abs(eig[0]))\n",
    "    return W.div(wsr).mul(sr)\n",
    "\n",
    "def cosFactor(av,bv):\n",
    "    #pdb.set_trace()\n",
    "    f = 0\n",
    "    cosSIM = 1.0\n",
    "    try:\n",
    "        currentCOS = np.dot(av, bv)/(np.linalg.norm(av)*np.linalg.norm(bv))\n",
    "    except: # catch *all* exceptions\n",
    "        f = sys.exc_info()[0]\n",
    "        print(f)\n",
    "        currentCOS = [0.0] # If error default orthogonal\n",
    "        \n",
    "    \n",
    "    if(not f):\n",
    "        if(np.any(np.isnan(currentCOS))): # If NaN default to orthogonal\n",
    "            currentCOS = [0.0]\n",
    "        cosSIM = 1 - currentCOS[0]\n",
    "    else:\n",
    "        print('Error f')\n",
    "    return cosSIM\n",
    "\n",
    "def resize_spaces(mn, mx, best):\n",
    "    #pdb.set_trace()\n",
    "    best_mn = np.min(best)\n",
    "    best_mx = np.max(best)\n",
    "    mn_bound = (best_mn-mn)/2\n",
    "    mx_bound = (mx -best_mx)/2\n",
    "    new_mn, new_mx = best_mn-mn_bound, best_mx+mx_bound\n",
    "    print(f'Best mn:{best_mn:.3f}\\t mn:{best_mx:.3f}\\n')\n",
    "    print(f'New bounds mn--mx: {mn_bound:.3f}--{mx_bound:.3f}')\n",
    "    return new_mn, new_mx\n",
    "\n",
    "def distribution(dataP,dataQ,mn,mx, bins=50):\n",
    "    emptyFlag = []\n",
    "    measureP,bnlocs = np.histogram(dataP, bins=bins, range=(mn,mx))\n",
    "    measureQ,_ = np.histogram(dataQ, bins=bins, range=(mn,mx))\n",
    "    for i in range(bins):\n",
    "        if((measureP[i] == 0) or (measureQ[i] == 0)):\n",
    "            emptyFlag.append(False)\n",
    "        else:\n",
    "            emptyFlag.append(True)\n",
    "    #pdb.set_trace()\n",
    "    measureP = measureP[emptyFlag]\n",
    "    measureQ = measureQ[emptyFlag]    \n",
    "    pmfP = (measureP)/np.linalg.norm(measureP)\n",
    "    pmfQ = (measureQ)/np.linalg.norm(measureQ)\n",
    "    kl = np.sum(rel_entr(pmfP,pmfQ))\n",
    "    return (kl,pmfP,pmfQ, bnlocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop for gp_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values to search with gp_optimize\n",
    "#space = [Real(.5,.7, name='a'),\n",
    "#         Real(.6,.8, name='sr'),\n",
    "#         Real(2,4, name='amp'),\n",
    "#         Real(.001,.5, name='ri'),\n",
    "#         Real(2,4, name='rr')\n",
    "#        ]\n",
    "\n",
    "#space = [Real(.001, 1, name='a'),\n",
    "#         Real(.001, 8., name='sr'),\n",
    "#         Real(.001, 1, name='amp'), \n",
    "#         Real(.001, 1., name='ri'),\n",
    "#         Real(.001, 5., name='rr')\n",
    "#        ]\n",
    "min_a, max_a = .001, 1.\n",
    "min_sr, max_sr = .001, 8.\n",
    "min_g, max_g = .001, 1.\n",
    "min_ri, max_ri = .001, 1.\n",
    "min_rr, max_rr = .001, 5.\n",
    "space = [Real(min_a, max_a, name='a'),\n",
    "                 Real(min_sr, max_sr, name='sr'),\n",
    "                 Real(min_g, max_g, name='amp'), \n",
    "                 Real(min_ri, max_ri, name='ri'),\n",
    "                 Real(min_rr, max_rr, name='rr')\n",
    "                ]\n",
    "\n",
    "@use_named_args(space)\n",
    "def loop(a=1.0,sr=1.0,amp=1.0,ri=1.0,rr=1.0):\n",
    "    start = time.time()\n",
    "    global running_error, s, counter, signal, N, \\\n",
    "           alphas, rhos, gammas, inScales, resScales# For run-time output\n",
    "    # Avoid copying from CPU to GPU    \n",
    "    # Init container variables directly on GPU\n",
    "    ut = torch.zeros((K,1),dtype=dtype, device=torch.device('cuda')) \n",
    "    tp = torch.zeros((K,1),dtype=dtype, device=torch.device('cuda'))\n",
    "    \n",
    "    # Init matrices directly on GPU\n",
    "    Wres = get_matrixGPU(N,rr,sr)\n",
    "    Win, Wfb, Wout = get_weight_matricesGPU(K,N,L,ri,RF)\n",
    "    Wnet = torch.cat((Win,Wres,Wfb),1) # Concat to one matrix for faster compute\n",
    "    xt, yt = set_vectorsGPU(N,L,rr) # On GPU random init x0 and container yt   \n",
    "    \n",
    "    # GPU containers for Phi and y in regression solve (bad naming... reused var name)\n",
    "    # Here states is the Phi matrix\n",
    "    states = torch.zeros((TRAINLENGTH, N+K),dtype=dtype, device='cuda:0')\n",
    "    targets = torch.zeros((TRAINLENGTH),dtype=dtype, device='cuda:0')\n",
    "    # Loop through training data and accumulate states for ridge-regression solve\n",
    "    for i in range(TRAINLENGTH):\n",
    "        ut[:,0] = s[i]                         # Forcing u[t] \n",
    "        tp[:,0] = s[i+1]                       # True target for prediction u[t+1] \n",
    "        uxy = torch.cat((ut,xt,yt),0)          # Concat vectors for use with Wnet\n",
    "        xt1 = update_res_stateGPU(Wnet,xt,uxy,a,amp) # x[t+1] = F(x[t],u[t])\n",
    "        xu = torch.transpose(torch.cat((xt1,ut),0),0,1) # Transpose as row for Phi\n",
    "        states[i,:] = xu[0,:]\n",
    "        xt, yt = xt1, tp \n",
    "\n",
    "    state = states.detach().cpu().numpy() \n",
    "    #target = targets.detach().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    ############################             Ridge Regression solve on CPU (fast!)\n",
    "    torch.cuda.synchronize()    # GPU threads were running asynchronous\n",
    "                                # Use signal since already sitting on CPU side\n",
    "    wout = rct.get_trained_weights(state[BURNIN:],\n",
    "                                   signal[BURNIN+1:TRAINLENGTH+1],\n",
    "                                   REG)\n",
    "                                # Move back to GPU\n",
    "    Wout = torch.from_numpy(wout.reshape(L,N+K)).type(dtype).cuda() # Trained Wout\n",
    "    torch.cuda.synchronize()    # Make sure synchronized before prediction pass\n",
    "    ############################\n",
    "    \n",
    "    # Container for all predictions... Burnin --> train --> test --> freerun\n",
    "    predictions = torch.zeros((M+int(FREERUN/deltaT),K),\n",
    "                              dtype=dtype,\n",
    "                              device=torch.device('cuda'))\n",
    "    # Reset new initial vectors for prediction pass\n",
    "    xt, yt = set_vectorsGPU(N,L,rr)\n",
    "    ut.fill_(0.0)\n",
    "    for i in range(M+int(FREERUN/deltaT)):\n",
    "        if(i < TRAINLENGTH):\n",
    "            ut[:,0] = s[i]\n",
    "        else:\n",
    "            #pdb.set_trace()\n",
    "            ut = yt\n",
    "        uxy = torch.cat((ut,xt,yt),0)\n",
    "        xt1 = update_res_stateGPU(Wnet,xt,uxy,a,amp)\n",
    "        xu = torch.cat((xt1,ut),0)\n",
    "        yt1 = predict_yGPU(Wout,xu)\n",
    "        #pdb.set_trace()\n",
    "        predictions[i] = yt1[:,0]\n",
    "        xt, yt = xt1, yt1\n",
    "\n",
    "    yHat_GPU = predictions.detach().cpu().numpy()  # Move predictions onto CPU (numpy)\n",
    "    \n",
    "    nrmse = np.ones((K,1))*1000\n",
    "    #if((np.any(np.isnan(yHat_GPU))) or (np.any(np.isinf(yHat_GPU)))):\n",
    "    #    nrmse = nrmse_fail\n",
    "    #else:\n",
    "    try:\n",
    "        for i in range(K):\n",
    "            nrmse[i,0] = rca.NRMSE(signal[TRAINLENGTH:TRAINLENGTH+TEST,i],\n",
    "                                   yHat_GPU[TRAINLENGTH:TRAINLENGTH+TEST,i],\n",
    "                                   MINMAXS[i])\n",
    "    except: \n",
    "        pass\n",
    "    #### Pearson Correlation <=> Cosine Distance    \n",
    "    #pdb.set_trace()\n",
    "    av = signal[TRAINLENGTH:TRAINLENGTH+TEST]\n",
    "    bv = np.squeeze(yHat_GPU[TRAINLENGTH:TRAINLENGTH+TEST])\n",
    "    dists = np.zeros(K)\n",
    "    for i in range(K):\n",
    "        avec = av[:,i].reshape(TEST,1)\n",
    "        bvec = bv[:,i].reshape(TEST,1)\n",
    "        num = np.squeeze(np.dot(avec.T,bvec))\n",
    "        den = np.linalg.norm(avec)*np.linalg.norm(bvec)\n",
    "        cosine_similarity = num/den\n",
    "        cosine_distance = 1 - cosine_similarity\n",
    "        dists[i] = cosine_distance\n",
    "        \n",
    "    loss = np.max(nrmse+dists)\n",
    "    if(np.isnan(loss) or (np.isinf(loss) or (loss > 1000.0))):\n",
    "        loss = 1000\n",
    "    \n",
    "    if(loss < running_error):\n",
    "        alphas.append(a)\n",
    "        rhos.append(sr)\n",
    "        gammas.append(amp)\n",
    "        inScales.append(ri)\n",
    "        resScales.append(rr)\n",
    "        running_error = loss\n",
    "        #wnet = Wnet.detach().cpu().numpy()\n",
    "        \n",
    "        plt.figure(figsize=(15,12))\n",
    "        plt.subplot(3,1,1)\n",
    "        plt.plot(signal[TRAINLENGTH-LEAD:,0], label='Target')\n",
    "        plt.plot(yHat_GPU[TRAINLENGTH-LEAD:,0], label='X pred')\n",
    "        plt.axvline(LEAD,c='r',linestyle='dashed')\n",
    "        plt.ylim(-20,20)\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(3,1,2)\n",
    "        plt.plot(signal[TRAINLENGTH-LEAD:,1], label='Target')\n",
    "        plt.plot(yHat_GPU[TRAINLENGTH-LEAD:,1], label='Y pred')\n",
    "        plt.axvline(LEAD,c='r',linestyle='dashed')\n",
    "        plt.ylim(-20,20)\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(3,1,3)\n",
    "        plt.plot(signal[TRAINLENGTH-LEAD:,2], label='Target')\n",
    "        plt.plot(yHat_GPU[TRAINLENGTH-LEAD:,2], label='Z pred')\n",
    "        plt.axvline(LEAD,c='r',linestyle='dashed')\n",
    "        plt.ylim(-20,20)\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        #np.save(f'./MultiModelL3D/Mats/L3D_it{counter}_{N}_Wnet',wnet)\n",
    "        #np.save(f'./MultiModelL3D/Preds/L3D_it{counter}_{N}_Preds',yHat_GPU)\n",
    "        #np.save(f'./MultiModelL3D/Params/L3D_it{counter}_{N}_InstanceParams',currParams)\n",
    "        print(f' Iter={counter} a={a:.3f} sr={sr:.3f} amp={amp:.3f}',\n",
    "              f' ri={ri:.3f} rr={rr:.3f} loss={loss:3f}\\n\\n')\n",
    "    print(f'Iter: {counter} #### Diagnostic {loss:3f}   Time {(time.time()-start):.2f}',\n",
    "          f' Best {running_error:.3f} NRMSE {np.max(nrmse):.3f} CD {np.max(dists):.3f}')\n",
    "    counter += 1\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Search with gp_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "CALLS = 100      \n",
    "s = torch.torch.from_numpy(signal).cuda().type(dtype)\n",
    "# \n",
    "size = [1000,950,900,850,800,750,700,650,600,550,500,\n",
    "        450,400,350,300,250,200,150,100,50]\n",
    "for ref in range(50):\n",
    "    start = time.time()\n",
    "    for N in [100]:\n",
    "        alphas = []\n",
    "        rhos = []\n",
    "        gammas = []\n",
    "        inScales = []\n",
    "        resScales = []\n",
    "        space = [Real(min_a, max_a, name='a'),\n",
    "                 Real(min_sr, max_sr, name='sr'),\n",
    "                 Real(min_g, max_g, name='amp'), \n",
    "                 Real(min_ri, max_ri, name='ri'),\n",
    "                 Real(min_rr, max_rr, name='rr')\n",
    "                ]\n",
    "        running_error = 1000\n",
    "        counter = 0 \n",
    "        print(f'********** {N} ***********')\n",
    "        result_gp = gp_minimize(loop, space, n_calls=CALLS,\n",
    "                                random_state=11, n_jobs=2, n_initial_points=100)\n",
    "        print(f'\\nBest result = {result_gp.fun}')\n",
    "        names = ['a','sr','amp','ri','rr']\n",
    "        for i in range(len(space)):\n",
    "            print(f'{names[i]} = {result_gp.x[i]}')\n",
    "        min_a, max_a   = resize_spaces(min_a, max_a, np.array(alphas))\n",
    "        min_sr, max_sr = resize_spaces(min_sr, max_sr, np.array(rhos))\n",
    "        min_g, max_g   = resize_spaces(min_g, max_g, np.array(gammas))\n",
    "        min_ri, max_ri = resize_spaces(min_ri, max_ri, np.array(inScales))\n",
    "        min_rr, max_rr = resize_spaces(min_rr, max_rr, np.array(resScales))\n",
    "        print('Refined search bounds:\\n')\n",
    "        print(f'Alpha ({min_a}, {max_a})\\n')\n",
    "        print(f'Rho ({min_sr}, {max_sr})\\n')\n",
    "        print(f'Gamma ({min_g}, {max_g})\\n')\n",
    "        print(f'r-in ({min_ri}, {max_ri})\\n')\n",
    "        print(f'r-res ({min_rr}, {max_rr})\\n')\n",
    "    end = time.time()-start\n",
    "    print(f'End Refinement Run {ref} Time {end:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiModel RC Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def rank_curve(cplus, tols):\n",
    "    rank_tols = []\n",
    "    for i in tols:\n",
    "        rank_tols.append(rca.rank(cplus, i))\n",
    "    return np.array(rank_tols)\n",
    "\n",
    "iteration = [149,135,63,14,67,38,128,140,38,63,119,7,86,28,149,102,49,68, 17,17]\n",
    "size = [1000,950,900,850,800,750,700,650,600,550,500,450,400,350,300,250,200,150,100,50]\n",
    "\n",
    "TOLS = [1/10**(x) for x in range(0,20)]\n",
    "mm_ranks = []\n",
    "for ctr,N in zip(iteration,size):\n",
    "    start = time.time()\n",
    "    fn_mats = f'./MultiModelL3D/Mats/L3D_it{ctr}_{N}_Wnet.npy'\n",
    "    fn_params = f'./MultiModelL3D/Params/L3D_it{ctr}_{N}_InstanceParams.npy'\n",
    "    p = np.load(fn_params, allow_pickle=True)\n",
    "    a,g = p[0],p[2]\n",
    "\n",
    "    Wr, Wi = rca.get_mats(fn_mats, 3, N)\n",
    "    xeq = np.zeros((N,1))\n",
    "    ueq = np.zeros((K,1))\n",
    "    A = rca.leaky_jacobian(xeq, ueq, a, g, Wi, Wr)\n",
    "    B = rca.partial_u(xeq, ueq, a, g, Wi, Wr)\n",
    "\n",
    "    Cplus = rca.reachable_matrix(A, B)\n",
    "    svs = np.linalg.svd(Cplus, compute_uv=False)\n",
    "    Cplus = Cplus/np.max(svs)\n",
    "    rkc = rank_curve(Cplus,TOLS)\n",
    "    v = np.argmax(np.gradient(rkc))-1\n",
    "    ave_rank = (rkc[v]+rkc[v+1])/2\n",
    "    print(f'Time {time.time()-start} Pair: iter {ctr} size {N} argmax {v} {v+1} tol {TOLS[v]} ave {ave_rank}')\n",
    "    mm_ranks.append(ave_rank)\n",
    "    \n",
    "np.save('./MultiModelL3D/L3D_MMranks',mm_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = np.max(signal[:TRAINLENGTH+TEST,:], axis=0)-np.min(signal[:TRAINLENGTH+TEST,:], axis=0)\n",
    "err_list = []\n",
    "for ctr,N in zip(iteration,size):\n",
    "    pred = np.load(f'./MultiModelL3D/Preds/L3D_it{ctr}_{N}_Preds.npy', allow_pickle=True)\n",
    "    nrmse = mean_squared_error(signal[TRAINLENGTH:TRAINLENGTH+TEST,:],pred[TRAINLENGTH:TRAINLENGTH+TEST,:],\n",
    "                               squared=False, multioutput='raw_values')\n",
    "    print(nrmse/minmax)\n",
    "    err_list.append(nrmse/minmax)\n",
    "np.save('./MultiModelL3D/L3D_mm_errors',np.array(err_list))\n",
    "\n",
    "plt.plot(err_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mm_ranks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array(mm_ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(np.array(mm_ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0.\n",
    "no_outliers = []\n",
    "for i in range(len(mm_ranks)):\n",
    "    if(i in [4,13,17]):\n",
    "        pass\n",
    "    else:\n",
    "        total += mm_ranks[i]\n",
    "        no_outliers.append(mm_ranks[i])\n",
    "total/(len(mm_ranks)-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no =np.array(no_outliers) \n",
    "np.mean(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
