{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1,'/home/bwhiteak/ChaosESN/ESN_utils/')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import rc_tools as rct\n",
    "import rc_analysis as rca\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "import pdb\n",
    "\n",
    "from skopt.space import Real,Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "\n",
    "from scipy.integrate import odeint\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "np.random.seed(11)\n",
    "torch.set_printoptions(precision=10)\n",
    "dtype = torch.float32 \n",
    "\n",
    "print(f'Python: {sys.version}')\n",
    "print(f'Numpy: {np.__version__}')\n",
    "print(f'Torch: {torch.__version__}')\n",
    "\n",
    "DEVICE = 'cuda:5'\n",
    "\n",
    "FREERUN = 20  # Extra predicition time-steps after test data\n",
    "deltaT = .02      # Number of extra free-running steps  int(20/.02) \n",
    "\n",
    "rho = 28.0\n",
    "sigma = 10.0\n",
    "beta = 8/3\n",
    "\n",
    "# Lorenz 1963\n",
    "def f(state, t):\n",
    "    x,y,z = state\n",
    "    return sigma*(y-x), x*(rho-z)-y, x*y - beta*z\n",
    "\n",
    "state0 = [1.,1.,1.]             # Initial point\n",
    "t = np.arange(0,300+FREERUN,deltaT)  # Total of 320 full steps with deltaT=.02\n",
    "states = odeint(f,state0,t)\n",
    "\n",
    "mu = np.mean(states, axis=0)       # Get mean for each of x,y,z\n",
    "signal = (states - mu)[:,[0,1,2]]  # Mean center the data\n",
    "M = signal.shape[0] - int(FREERUN/deltaT)  # Length of train plus test... no freerun\n",
    "K = 3                                  # Input dimension\n",
    "L = 3                                  # Output dimension\n",
    "RF = .5                                # For feedback <--- not implemented\n",
    "TEST = 1000                            # length of test\n",
    "LEAD = 100                            # Number of points to plot before test\n",
    "BURNIN = 100                           # Number of steps ignored for random x0 to fade\n",
    "REG = 1e-8                             # Regularization factor for ridge regression\n",
    "TRAINLENGTH = M-TEST    \n",
    "\n",
    "MINMAXS = np.max(signal[:TRAINLENGTH+TEST],axis=0)-np.min(signal[:TRAINLENGTH+TEST],axis=0)\n",
    "STD = np.std(signal[:TRAINLENGTH+TEST],axis=0)\n",
    "RGS = [(-19.5,19.5),(-27,27),(-25,25)]\n",
    "BINS = 50\n",
    "\n",
    "print(f'Signal length M={M}')\n",
    "print(f'Normalizing value MM is {MINMAXS}')\n",
    "print(f'std = {STD}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_matricesGPU(k,n,l,ri,ro):\n",
    "    win = torch.rand((n,k),dtype=dtype,\n",
    "                      device=torch.device(DEVICE)).sub(.5).mul(ri)\n",
    "    wfb = torch.zeros((n,l),dtype=dtype, device=torch.device(DEVICE))\n",
    "    wout = torch.rand((l,n+k),dtype=dtype,\n",
    "                      device=torch.device(DEVICE)).sub(.5).mul(ro)\n",
    "    return win, wfb, wout\n",
    "\n",
    "def set_vectorsGPU(n,l,r):\n",
    "    x0 = torch.rand((n,1),dtype=dtype,\n",
    "                      device=torch.device(DEVICE)).sub(.5).mul(r)\n",
    "    y0 = torch.zeros((l,1),dtype=dtype, device=torch.device(DEVICE))\n",
    "    return x0, y0\n",
    "\n",
    "def update_res_stateGPU(wnet,xt,uxy,a,g):\n",
    "    z = torch.matmul(wnet,uxy)\n",
    "    return torch.mul(xt,1-a) + torch.mul(torch.tanh(z),a*g)\n",
    "\n",
    "def predict_yGPU(wout,xu):\n",
    "    return torch.matmul(wout, xu)\n",
    "\n",
    "def get_matrixGPU(n,r,sr):\n",
    "    A = (torch.rand((n,n),dtype=dtype,\n",
    "                   device=torch.device(DEVICE))-.5)*r\n",
    "    At = torch.transpose(A,0,1)\n",
    "    D = torch.diag(torch.diag(A))   \n",
    "    W = A + At - D\n",
    "    eig = torch.eig(W, eigenvectors=False)\n",
    "    wsr = torch.max(torch.abs(eig[0]))\n",
    "    return W.div(wsr).mul(sr)\n",
    "\n",
    "def resize_spaces(mn, mx, best, isAlpha=False):\n",
    "    #pdb.set_trace()\n",
    "    if(best.size==0):\n",
    "        new_mn = np.max([0, mn - .5*mn])\n",
    "        new_mx = 1.5*mx\n",
    "    else:\n",
    "        best_mn = np.min(best)\n",
    "        best_mx = np.max(best)\n",
    "        mn_bound = (best_mn-mn)/2\n",
    "        mx_bound = (mx -best_mx)/2\n",
    "        new_mn, new_mx = best_mn-mn_bound, best_mx+mx_bound\n",
    "        print(f'\\nBest mn:{best_mn:.3f}\\t mn:{best_mx:.3f}')\n",
    "        print(f'New bounds mn--mx: {mn_bound:.3f}--{mx_bound:.3f}')\n",
    "    if(isAlpha):\n",
    "        if(new_mx>1):\n",
    "            new_mx = 1\n",
    "    \n",
    "    return new_mn, new_mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop for gp_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from json import JSONEncoder\n",
    "\n",
    "# numpy arrays cannot be written to json \n",
    "# convert to list\n",
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self,obj):\n",
    "        if isinstance(obj,np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self,obj)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_a, max_a = .5, .9\n",
    "min_sr, max_sr = 1.1, 1.7\n",
    "min_g, max_g = .2, .24\n",
    "min_ri, max_ri = .01, .1\n",
    "min_rr, max_rr = .85, 2.7\n",
    "space = [Real(min_a, max_a, name='a'),\n",
    "         Real(min_sr, max_sr, name='sr'),\n",
    "         Real(min_ri, max_ri, name='ri'),\n",
    "         Real(min_rr, max_rr, name='rr')\n",
    "        ]\n",
    "\n",
    "@use_named_args(space)\n",
    "def loop(a=1.0,sr=1.0,ri=1.0,rr=1.0):\n",
    "    start = time.time()\n",
    "    amp = 1.\n",
    "    global running_error, s, counter, signal, N, ref, rn, \\\n",
    "           alphas, rhos, gammas, inScales, dict_model, \\\n",
    "           model_counter, error_per_N, error_over_N, best_N_model\n",
    "    \n",
    "    # Avoid copying from CPU to GPU    \n",
    "    # Init container variables directly on GPU\n",
    "    ut = torch.zeros((K,1),dtype=dtype, device=torch.device(DEVICE)) \n",
    "    tp = torch.zeros((K,1),dtype=dtype, device=torch.device(DEVICE))\n",
    "    \n",
    "    # Init matrices directly on GPU\n",
    "    Wres = get_matrixGPU(N,rr,sr)\n",
    "    Win, Wfb, Wout = get_weight_matricesGPU(K,N,L,ri,RF)\n",
    "    Wnet = torch.cat((Win,Wres,Wfb),1) # Concat to one matrix for faster compute\n",
    "    xt, yt = set_vectorsGPU(N,L,rr) # On GPU random init x0 and container yt   \n",
    "    \n",
    "    # GPU containers for Phi and y in regression solve (bad naming... reused var name)\n",
    "    # Here states is the Phi matrix\n",
    "    states = torch.zeros((TRAINLENGTH, N+K),dtype=dtype,\n",
    "                         device=DEVICE)\n",
    "    targets = torch.zeros((TRAINLENGTH),dtype=dtype,\n",
    "                        device=DEVICE)\n",
    "    # Loop through training data and accumulate states for ridge-regression solve\n",
    "    for i in range(TRAINLENGTH):\n",
    "        ut[:,0] = s[i]                         # Forcing u[t] \n",
    "        tp[:,0] = s[i+1]                       # True target for prediction u[t+1] \n",
    "        uxy = torch.cat((ut,xt,yt),0)          # Concat vectors for use with Wnet\n",
    "        xt1 = update_res_stateGPU(Wnet,xt,uxy,a,amp) # x[t+1] = F(x[t],u[t])\n",
    "        xu = torch.transpose(torch.cat((xt1,ut),0),0,1).to(DEVICE) # Transpose as row for Phi\n",
    "        states[i,:] = xu[0,:]\n",
    "        xt, yt = xt1, tp \n",
    "\n",
    "    state = states.detach().cpu().numpy() \n",
    "    #target = targets.detach().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    ############################             Ridge Regression solve on CPU (fast!)\n",
    "    torch.cuda.synchronize()    # GPU threads were running asynchronous\n",
    "                                # Use signal since already sitting on CPU side\n",
    "    wout = rct.get_trained_weights(state[BURNIN:],\n",
    "                                   signal[BURNIN+1:TRAINLENGTH+1],\n",
    "                                   REG)\n",
    "                                # Move back to GPU\n",
    "    Wout = torch.from_numpy(wout.reshape(L,N+K)).type(dtype).cuda(DEVICE) # Trained Wout\n",
    "    torch.cuda.synchronize()    # Make sure synchronized before prediction pass\n",
    "    ############################\n",
    "    \n",
    "    # Container for all predictions... Burnin --> train --> test --> freerun\n",
    "    predictions = torch.zeros((M+int(FREERUN/deltaT),K),\n",
    "                              dtype=dtype,\n",
    "                              device=torch.device(DEVICE))\n",
    "    # Reset new initial vectors for prediction pass\n",
    "    xt, yt = set_vectorsGPU(N,L,rr)\n",
    "    ut.fill_(0.0)\n",
    "    for i in range(M+int(FREERUN/deltaT)):\n",
    "        if(i < TRAINLENGTH):\n",
    "            ut[:,0] = s[i]\n",
    "        else:\n",
    "            #pdb.set_trace()\n",
    "            ut = yt\n",
    "        uxy = torch.cat((ut,xt,yt),0)\n",
    "        xt1 = update_res_stateGPU(Wnet,xt,uxy,a,amp)\n",
    "        xu = torch.cat((xt1,ut),0)\n",
    "        yt1 = predict_yGPU(Wout,xu)\n",
    "        #pdb.set_trace()\n",
    "        predictions[i] = yt1[:,0]\n",
    "        xt, yt = xt1, yt1\n",
    "\n",
    "    yHat_GPU = predictions.detach().cpu().numpy()  # Move predictions onto CPU (numpy)\n",
    "    \n",
    "    nrmse3D = np.ones((K,1))*1000\n",
    "    try:\n",
    "        for i in range(K):\n",
    "            nrmse3D[i,0] = rca.NRMSE(signal[TRAINLENGTH:TRAINLENGTH+TEST,i],\n",
    "                                   yHat_GPU[TRAINLENGTH:TRAINLENGTH+TEST,i],\n",
    "                                   MINMAXS[i])\n",
    "    except: \n",
    "        pass\n",
    "    #### Pearson Correlation <=> Cosine Distance    \n",
    "    av = signal[TRAINLENGTH:TRAINLENGTH+TEST]\n",
    "    bv = np.squeeze(yHat_GPU[TRAINLENGTH:TRAINLENGTH+TEST])\n",
    "    dists = np.zeros(K)\n",
    "    for i in range(K):\n",
    "        avec = av[:,i].reshape(TEST,1)\n",
    "        bvec = bv[:,i].reshape(TEST,1)\n",
    "        num = np.squeeze(np.dot(avec.T,bvec))\n",
    "        den = np.linalg.norm(avec)*np.linalg.norm(bvec)\n",
    "        cosine_similarity = num/den\n",
    "        cosine_distance = 1 - cosine_similarity\n",
    "        dists[i] = cosine_distance\n",
    "    dist = np.max(dists)\n",
    "    nrmse = np.max(nrmse3D)\n",
    "    loss = np.max(nrmse3D+dists)\n",
    "    if(np.isnan(loss) or (np.isinf(loss) or (loss > 1000.0))):\n",
    "        loss = 1000\n",
    "    \n",
    "    if((loss < running_error) and (nrmse < .17)):\n",
    "        print(f'Dist {dist:3f}')\n",
    "        running_error = loss\n",
    "        wnet = Wnet.detach().cpu().numpy()\n",
    "        currentParams = np.array([a,sr,amp,ri,rr,loss])\n",
    "        if(error_over_N > running_error):\n",
    "            print('\\n\\nNew N best!!!!!!!!!!!!\\n\\n')\n",
    "            error_over_N = running_error  #set the lowest error\n",
    "            best_N_model = [N,ref,rn,counter]\n",
    "            states_dict = {'States': state}\n",
    "            with open(f'Dicts/States/states_L3D_{N}.json', 'w') as fp:\n",
    "                json.dump(states_dict, fp, cls=NumpyArrayEncoder)\n",
    "            dict_model[str(N)] = {'Wnet': wnet,\n",
    "                                  'Wout': wout,\n",
    "                                  'Preds': yHat_GPU,\n",
    "                                  'Params': currentParams}\n",
    "            print(best_N_model)\n",
    "        \n",
    "        alphas.append(a)\n",
    "        rhos.append(sr)\n",
    "        gammas.append(amp)\n",
    "        inScales.append(ri)\n",
    "        resScales.append(rr)\n",
    "                \n",
    "        fig = plt.figure(figsize=(15,12))\n",
    "        plt.subplot(3,1,1)\n",
    "        plt.plot(signal[TRAINLENGTH-LEAD:,0], label='Target')\n",
    "        plt.plot(yHat_GPU[TRAINLENGTH-LEAD:,0], label='X pred')\n",
    "        plt.axvline(LEAD,c='r',linestyle='dashed')\n",
    "        plt.ylim(-20,20)\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(3,1,2)\n",
    "        plt.plot(signal[TRAINLENGTH-LEAD:,1], label='Target')\n",
    "        plt.plot(yHat_GPU[TRAINLENGTH-LEAD:,1], label='Y pred')\n",
    "        plt.axvline(LEAD,c='r',linestyle='dashed')\n",
    "        plt.ylim(-20,20)\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(3,1,3)\n",
    "        plt.plot(signal[TRAINLENGTH-LEAD:,2], label='Target')\n",
    "        plt.plot(yHat_GPU[TRAINLENGTH-LEAD:,2], label='Z pred')\n",
    "        plt.axvline(LEAD,c='r',linestyle='dashed')\n",
    "        plt.ylim(-20,20)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        model_counter += 1\n",
    "        error_per_N.append(nrmse3D)\n",
    "\n",
    "        print(f' Iter={counter} a={a:.3f} sr={sr:.3f} amp={amp:.3f}',\n",
    "              f' ri={ri:.3f} rr={rr:.3f} loss={loss:3f}\\n\\n')\n",
    "    print(f'Iter: {counter} #### Diagnostic {loss:3f}   Time {(time.time()-start):.2f}',\n",
    "          f' Best {running_error:.3f} NRMSE {np.max(nrmse):.3f} CD {np.max(dists):.3f}')\n",
    "    counter += 1\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Search with gp_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CALLS = 100      \n",
    "s = torch.torch.from_numpy(signal).cuda(DEVICE).type(dtype)\n",
    "# Skipped N=1000,900,800\n",
    "#size = [300,50,40,30,20,10]\n",
    "size = [1000,800,600,400,300,100,\n",
    "        50,40,30,20,28,26,24,22,18,16,14,12,10]\n",
    "rand_state = [11,37,3,24,91]\n",
    "\n",
    "dict_counters = {}\n",
    "dict_model = {}\n",
    "for N in size:\n",
    "    model_counter = 0\n",
    "    error_per_N =  []\n",
    "    best_N_model = [N,0,0,0] \n",
    "    \n",
    "    min_a, max_a = .5, .9\n",
    "    min_sr, max_sr = 1.1, 1.7\n",
    "    min_g, max_g = .2, .24\n",
    "    min_ri, max_ri = .01, .1\n",
    "    min_rr, max_rr = .85, 2.7\n",
    "\n",
    "    space = [Real(min_a, max_a, name='a'),\n",
    "             Real(min_sr, max_sr, name='sr'),\n",
    "             Real(min_ri, max_ri, name='ri'),\n",
    "             Real(min_rr, max_rr, name='rr')\n",
    "            ]\n",
    "    error_over_N = 1000\n",
    "    for ref in range(5):\n",
    "        \n",
    "        alphas = []\n",
    "        rhos = []\n",
    "        gammas = []\n",
    "        inScales = []\n",
    "        resScales = []\n",
    "        \n",
    "        for rn in range(5):\n",
    "            start = time.time()\n",
    "            running_error = 1000\n",
    "            counter = 0 \n",
    "            print(f'********** Size{N} ref {ref} -- Run {rn} ***********')\n",
    "            result_gp = gp_minimize(loop,\n",
    "                                    space,\n",
    "                                    n_calls=CALLS,\n",
    "                                    random_state=rand_state[rn],\n",
    "                                    n_jobs=4,\n",
    "                                    n_initial_points=100)\n",
    "            end = time.time()-start\n",
    "            print(f'End Refinement Run {ref} Time {end:.3f}')\n",
    "            print(f'\\nRun: {rn} Best result = {result_gp.fun}')\n",
    "            names = ['a','sr','amp','ri','rr']\n",
    "            for i in range(len(space)):\n",
    "                print(f'{names[i]} = {result_gp.x[i]}')\n",
    "                \n",
    "        min_a, max_a   = resize_spaces(min_a, max_a,\n",
    "                                       np.array(alphas),\n",
    "                                       isAlpha=True)\n",
    "        min_sr, max_sr = resize_spaces(min_sr, max_sr, np.array(rhos))\n",
    "        min_g, max_g   = resize_spaces(min_g, max_g, np.array(gammas))\n",
    "        min_ri, max_ri = resize_spaces(min_ri, max_ri, np.array(inScales))\n",
    "        min_rr, max_rr = resize_spaces(min_rr, max_rr, np.array(resScales))\n",
    "        print('Refined search bounds:\\n')\n",
    "        print(f'Alpha ({min_a}, {max_a})\\n')\n",
    "        print(f'Rho ({min_sr}, {max_sr})\\n')\n",
    "        print(f'Gamma ({min_g}, {max_g})\\n')\n",
    "        print(f'r-in ({min_ri}, {max_ri})\\n')\n",
    "        print(f'r-res ({min_rr}, {max_rr})\\n')\n",
    "        \n",
    "        \n",
    "    print(model_counter)\n",
    "    print(np.mean(np.array(error_per_N),axis=0))\n",
    "    if(model_counter == 0):\n",
    "        dict_counters[f'{str(N)}'] = {'numModels': model_counter,\n",
    "                                      'meanError': [np.nan,np.nan,np.nan],\n",
    "                                      'varError' : [np.nan,np.nan,np.nan]}\n",
    "    else:\n",
    "        print(np.mean(np.array(error_per_N),axis=1))\n",
    "        dict_counters[f'{str(N)}'] = {'numModels': model_counter,\n",
    "                                      'meanError': np.mean(np.array(error_per_N),axis=0).tolist(),\n",
    "                                      'varError' : np.var(np.array(error_per_N),axis=0).tolist()}\n",
    "    with open('Dicts/diag_L3D_sm.json', 'w') as fp:\n",
    "        json.dump(dict_counters, fp, cls=NumpyArrayEncoder)\n",
    "    with open('Dicts/models_L3D_sm.json', 'w') as fp:\n",
    "        json.dump(dict_model, fp, cls=NumpyArrayEncoder)\n",
    "print(dict_counters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 24\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"text.usetex\"] = True \n",
    "plt.rcParams[\"axes.xmargin\"] = 0 \n",
    "plt.rcParams[\"axes.titlesize\"] = fontsize \n",
    "plt.rcParams[\"axes.labelsize\"] = fontsize\n",
    "plt.rcParams[\"xtick.labelsize\"] = fontsize\n",
    "plt.rcParams[\"ytick.labelsize\"] = fontsize\n",
    "plt.rcParams[\"axes.labelsize\"] = fontsize\n",
    "plt.rcParams[\"font.weight\"] = \"heavy\"\n",
    "plt.rcParams[\"axes.labelweight\"] = \"heavy\"\n",
    "\n",
    "fpath = 'Dicts/diag_L3D_sm.json'\n",
    "with open(fpath,'r') as j:\n",
    "    dict_diag = json.loads(j.read())\n",
    "\n",
    "fpath = 'Dicts/models_L3D_sm.json'\n",
    "with open(fpath,'r') as j:\n",
    "    dict_models = json.loads(j.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size = [300,50,40,30,20,10]\n",
    "variable = ['X','Y','Z']\n",
    "\n",
    "fig, ax = plt.subplots(3, figsize=(10,9))\n",
    "for sp in range(3):\n",
    "    ax[sp].set_title(f'{variable[sp]} Predictions')\n",
    "    for n in size:\n",
    "        preds = np.array(dict_models[str(n)]['Preds'])\n",
    "        error_testset = rca.NRMSE(signal[TRAINLENGTH:TRAINLENGTH + TEST,sp],\n",
    "                              preds[TRAINLENGTH:TRAINLENGTH + TEST,sp],\n",
    "                              MINMAXS[sp])\n",
    "        kl,_,_,_ = rca.distribution(signal[TRAINLENGTH:TRAINLENGTH + TEST,sp],\n",
    "                                    preds[TRAINLENGTH:TRAINLENGTH + TEST,sp],\n",
    "                                     np.min(signal[:TRAINLENGTH+TEST,sp]),\n",
    "                                     np.max(signal[:TRAINLENGTH+TEST,sp]),\n",
    "                                     bins=50)\n",
    "        print(f'Dim={sp} N={n}   Error = {error_testset.round(3)} Div = {kl:.3f}')\n",
    "        ax[0].plot(signal[TRAINLENGTH:TRAINLENGTH + TEST,sp], color='k',\n",
    "                  label='target', alpha=0)\n",
    "        if(sp==2):\n",
    "            ax[sp].plot(signal[TRAINLENGTH:TRAINLENGTH + TEST,sp], color='k')\n",
    "            ax[sp].plot(preds[TRAINLENGTH:TRAINLENGTH + TEST,sp],\n",
    "                     linestyle='dotted', label=f'N={n}')\n",
    "        else:\n",
    "            ax[sp].plot(signal[TRAINLENGTH:TRAINLENGTH + TEST,sp], color='k')\n",
    "            ax[sp].plot(preds[TRAINLENGTH:TRAINLENGTH + TEST,sp],\n",
    "                     linestyle='dotted')\n",
    "plt.legend(bbox_to_anchor=(1.11, 2.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fsolve\n",
    "def rank_curve(cplus, tols):\n",
    "    rank_tols = []\n",
    "    for i in tols:\n",
    "        rank_tols.append(rca.rank(cplus, i))\n",
    "    return np.array(rank_tols)\n",
    "\n",
    "K = 3\n",
    "L = 3\n",
    "tols = [1/10**x for x in range(0,30)]\n",
    "plt.figure()\n",
    "for n in size:\n",
    "    mat = np.array(dict_models[str(n)]['Wnet'])\n",
    "    Wr, Wi = rca.get_mats(None, K,n, matrix=mat)\n",
    "    # params [alpha, spectralradius, gamma, ri, rr, loss]\n",
    "    p = dict_models[str(n)]['Params']\n",
    "    a,g = p[0], p[2]\n",
    "    print(f'Alpha {a:2f} --- Gamma {g:2f}')\n",
    "    x0 = np.zeros((n,1))\n",
    "    u0 = np.zeros((K,1))\n",
    "    A = rca.leaky_jacobian(x0, u0, a, g, Wi, Wr)\n",
    "    B = rca.partial_u(x0, u0, a, g, Wi, Wr)\n",
    "    rhoA = np.max(np.abs(rca.eig_spectrum(A)))\n",
    "    Cn = np.nan_to_num(rca.reachable_matrix(A,B))\n",
    "    if(K != 3): # Square Cn\n",
    "        Cn = Cn/np.max(np.abs(rca.eig_spectrum(Cn)))\n",
    "    else:            # Non-square Cn\n",
    "        Cn = Cn/np.max(np.abs(np.linalg.svd(Cn, compute_uv=False)))\n",
    "\n",
    "    rkc = rank_curve(Cn, tols)\n",
    "    v = np.argmax(np.gradient(rkc))\n",
    "    plt.plot(rkc, label=f'N={n}')\n",
    "    plt.vlines([v],0,50, color='k')\n",
    "    ave_rank = (rkc[v]+rkc[v+1])//2\n",
    "    print(f'Ave rank for N={n} is {ave_rank} sr={p[1]:3f} v={v} Tolerance {tols[v]} Rho A {rhoA.round(3)}')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim(0,50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.gridspec as gridspec\n",
    "from scipy.signal import argrelmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 30\n",
    "K = 3\n",
    "v = 3\n",
    "pred = np.array(dict_models[str(30)]['Preds'])\n",
    "start, end= 13900,15000\n",
    "p = dict_models[str(n)]['Params']\n",
    "mat = np.array(dict_models[str(N)]['Wnet'])\n",
    "Wr, Wi = rca.get_mats(None, K,N, matrix=mat)\n",
    "sig_rks = rca.rank_along_trajectory( Wr, Wi, p[0], p[2],\n",
    "                            signal[start:end], N, K, tols[v])\n",
    "pred_rks = rca.rank_along_trajectory( Wr, Wi, p[0], p[2],\n",
    "                            pred[start:end],N, K, tols[v])\n",
    "\n",
    "top,bottom  = 13900,15000\n",
    "mu = np.array([.56018255, .55704211, 23.59124571])\n",
    "\n",
    "gs = gridspec.GridSpec(2, 1)\n",
    "fig = plt.figure(figsize=(12,24))\n",
    "ax1 = fig.add_subplot(gs[0], projection='3d')\n",
    "ax1.plot(signal[14000:,0]+mu[0],\n",
    "         signal[14000:,1]+mu[1],\n",
    "         signal[14000:,2]+mu[2],\n",
    "         c='k', label='$L3D$')\n",
    "ax1.plot(pred[14000:,0]+mu[0],\n",
    "         pred[14000:,1]+mu[1],\n",
    "         pred[14000:,2]+mu[2],\n",
    "         c='r', label='$\\widehat{\\mathbf{y}},$ $N=30$', alpha=.5)\n",
    "ax1.set_xlabel('$v^{(1)}_t$', fontsize=26, color='black')\n",
    "ax1.set_ylabel('$v^{(2)}_t$', fontsize=26, color='black')\n",
    "ax1.set_zlabel('$v^{(3)}_t$', fontsize=26, color='black')\n",
    "ax1.w_xaxis.set_pane_color ((0., 0., 0., 0.))\n",
    "ax1.w_yaxis.set_pane_color ((0., 0., 0., 0.))\n",
    "ax1.w_zaxis.set_pane_color ((0., 0., 0., 0.))\n",
    "ax1.xaxis.labelpad = 20\n",
    "ax1.yaxis.labelpad = 20\n",
    "ax1.zaxis.labelpad = 20\n",
    "ax1.set_zticklabels([10,20,30,40])\n",
    "ax1.legend(fontsize=24,\n",
    "           labelcolor='black',\n",
    "           ncol=2,\n",
    "           handlelength=.5,\n",
    "           borderpad=.2,\n",
    "           borderaxespad=.2)\n",
    "ax1.text(-.2, 1.,310,s='$(\\mathbf{a})$', transform=ax1.transAxes, \n",
    "            size=30, weight='bold')\n",
    "\n",
    "gs1 = gs[1].subgridspec(2,1, hspace=0)\n",
    "ax2 = plt.subplot(gs1[0])\n",
    "ax2.text(-0.2, 1.,s='$(\\mathbf{b})$', transform=ax2.transAxes, \n",
    "            size=30, weight='bold')\n",
    "ax2.plot(signal[top:bottom-500, 0], color='k', label='$v^{(3)}_t$')\n",
    "ax2.plot(pred[top:bottom-500, 0],'coral', ms=3, label = '$\\widehat{y}^{(3)}$')\n",
    "ax2.axvline(100, color='k', linestyle='dashed')\n",
    "ax2.axvline(278, color='r', linestyle='dashed')\n",
    "ax2.set_ylabel('$L3D -\\mu_{L3D}$', labelpad=10)\n",
    "ax2.set_ylim(-25,25)\n",
    "ax2.legend(loc='lower right',\n",
    "           ncol=2 ,\n",
    "           handlelength=.5,\n",
    "           fontsize=22,\n",
    "           borderpad=.2,\n",
    "           borderaxespad=.2)\n",
    "ax2.set_xticks([])\n",
    "\n",
    "ax3 = plt.subplot(gs1[1])\n",
    "ax3.plot([x for x in range(top,bottom-500)],\n",
    "         sig_rks[:-500], color='k',\n",
    "         label='$L3D$', alpha=.8)\n",
    "ax3.plot([x for x in range(top,bottom-500)],\n",
    "         pred_rks[:-500], color= 'coral',\n",
    "         label='$\\widehat{\\mathbf{y}},$ $N=30$', alpha=.6)\n",
    "\n",
    "ax3.set_ylabel('$\\mathrm{rank}(\\mathbf{\\mathcal{C}}_{25};10^{-8})$', labelpad=22)\n",
    "ax3.set_xlabel('Time-step $t$')\n",
    "ax3.text(-0.2, 0,s='$(\\mathbf{c})$', transform=ax2.transAxes, \n",
    "            size=30, weight='bold')\n",
    "ax3.legend(handlelength=.5,\n",
    "           ncol=2,\n",
    "           loc='lower right',\n",
    "           fontsize=22,\n",
    "           borderpad=.2,\n",
    "           borderaxespad=.2)\n",
    "ax3.set_xticks([13900,14000,14100,14200,14300,14400])\n",
    "ax3.set_xticklabels([-100,0,100,200,300,400])\n",
    "\n",
    "#maxradii = np.array(list(set((argrelmax(sigradius)[0]).tolist()) & set((np.where(sigradius>1)[0]).tolist())))\n",
    "ax3.axvline(14000, color='k', linestyle='dashed')\n",
    "ax3.axvline(14178, color='r', linestyle='dashed')\n",
    "#ax3.set_ylim(27,29)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"../PlotNBs/NBoutputs/L3D_lines_combined.pdf\", format='pdf', bbox_inches='tight', pad_inches=.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rxy(x,y):\n",
    "    return np.dot(x.T,y)/(np.linalg.norm(x)*np.linalg.norm(y))\n",
    "\n",
    "start = TRAINLENGTH - 1000\n",
    "stop = M+FREERUN\n",
    "k_list = [30]\n",
    "fig, ax = plt.subplots(3, figsize=(10,9))\n",
    "for sp in range(3):\n",
    "    for k in k_list:\n",
    "        lengthTC = (stop-start)-k\n",
    "        trainCorr = np.zeros(lengthTC) # 21000-k\n",
    "        pred = np.array(dict_models[str(k)]['Preds'])\n",
    "        for j in range(start,stop-k):\n",
    "            tar = signal[j:j+k,sp].reshape((k,1))\n",
    "            prd = pred[j:j+k,sp].reshape((k,1))\n",
    "            trainCorr[j-start] = Rxy(tar,prd)\n",
    "        minVal = trainCorr[:1000].min()\n",
    "        threshold = minVal*.95\n",
    "        thresholdLoc = np.where(trainCorr[1000:]<threshold)[0][0]\n",
    "        print(f'k-size={k} Trainingset min={minVal.round(3)}  threshold={threshold:.3f}',\n",
    "              f' Location={thresholdLoc}')\n",
    "        #ax[sp].plot(trainCorr[500:1300], color='r', label=f'k={k}')\n",
    "    ax[sp].plot(signal[TRAINLENGTH-500:TRAINLENGTH+TEST,sp], color='k', label='target')\n",
    "    ax[sp].plot(pred[TRAINLENGTH-500:TRAINLENGTH+TEST,sp], label='pred')\n",
    "    ax[sp].axvline(500+thresholdLoc,color='r', label='diverged')\n",
    "    ax[sp].axvline(500,color='k',linestyle='dashed')\n",
    "    ax[sp].set_ylabel('$\\mathbf{R}_{xy}$')\n",
    "    ax[sp].set_xlabel('Time-steps $t$ samples are: Train $[0,1000]$, Test $[1000,1500]$')\n",
    "    ax[sp].set_xticklabels([-500,-250,0,250,500,750])\n",
    "    plt.legend(fontsize=24,bbox_to_anchor=(1.31, 2.05))\n",
    "    ax[0].set_title('Prediction divergence (red lines) by $\\mathbf{R}_{xy}[k]$ for $k=30$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
