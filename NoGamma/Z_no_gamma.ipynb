{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cuda:6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.8.12 (default, Oct 12 2021, 13:49:34) \n",
      "[GCC 7.5.0]\n",
      "Numpy: 1.21.2\n",
      "Torch: 1.10.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1,'/home/bwhiteak/ChaosESN/ESN_utils/')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import rc_tools as rct\n",
    "import rc_analysis as rca\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.signal import argrelextrema\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "import pdb\n",
    "\n",
    "from skopt.space import Real,Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "\n",
    "from scipy.integrate import odeint\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#from jupyterthemes import jtplot\n",
    "#jtplot.style(theme='solarizedd', context='notebook',\n",
    "#             ticks=True, grid=False)\n",
    "\n",
    "np.random.seed(11)\n",
    "torch.set_printoptions(precision=10)\n",
    "dtype = torch.float32 \n",
    "\n",
    "print(f'Python: {sys.version}')\n",
    "print(f'Numpy: {np.__version__}')\n",
    "print(f'Torch: {torch.__version__}')\n",
    "\n",
    "DEVICE = 'cuda:6'\n",
    "\n",
    "FREERUN = 20\n",
    "DT = .02\n",
    "\n",
    "rho = 28.0\n",
    "sigma = 10.0\n",
    "beta = 8/3\n",
    "\n",
    "def f(state, t):\n",
    "    x,y,z = state\n",
    "    return sigma*(y-x), x*(rho-z)-y, x*y - beta*z\n",
    "\n",
    "state0 = [1.,1.,1.]\n",
    "t = np.arange(0,300+FREERUN,DT)\n",
    "states = odeint(f,state0,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal length M=15000\n",
      "Normalizing value max-min id 46.872\n",
      "Normalizing value max-min id 8.567\n"
     ]
    }
   ],
   "source": [
    "log_z = np.log(states[:,2])\n",
    "\n",
    "MU_X = np.mean(log_z)\n",
    "signal = log_z-MU_X\n",
    "\n",
    "M = signal.shape[0] - int(FREERUN/DT)\n",
    "K = 1\n",
    "L = 1\n",
    "RF = .5\n",
    "TEST = 1000\n",
    "LEAD = 100\n",
    "BURNIN = 100\n",
    "REG = 1e-8\n",
    "TRAINLENGTH = M-TEST\n",
    "\n",
    "\n",
    "MINMAX = np.max(states[:TRAINLENGTH+TEST,2]) - \\\n",
    "         np.min(states[:TRAINLENGTH+TEST,2])\n",
    "STD = np.std(states[:TRAINLENGTH+TEST,2])\n",
    "\n",
    "BINS = 50\n",
    "\n",
    "print(f'Signal length M={M}')\n",
    "print(f'Normalizing value max-min id {MINMAX:.3f}')\n",
    "print(f'Normalizing value max-min id {STD:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_matricesGPU(k,n,l,ri,ro):\n",
    "    win = torch.rand((n,k),dtype=dtype,\n",
    "                      device=torch.device(DEVICE)).sub(.5).mul(ri)\n",
    "    wfb = torch.zeros((n,l),dtype=dtype, device=torch.device(DEVICE))\n",
    "    wout = torch.rand((l,n+k),dtype=dtype,\n",
    "                      device=torch.device(DEVICE)).sub(.5).mul(ro)\n",
    "    return win, wfb, wout\n",
    "\n",
    "def set_vectorsGPU(n,l,r):\n",
    "    x0 = torch.rand((n,1),dtype=dtype,\n",
    "                      device=torch.device(DEVICE)).sub(.5).mul(r)\n",
    "    y0 = torch.zeros((l,1),dtype=dtype, device=torch.device(DEVICE))\n",
    "    return x0, y0\n",
    "\n",
    "def update_res_stateGPU(wnet,xt,uxy,a,g):\n",
    "    z = torch.matmul(wnet,uxy)\n",
    "    return torch.mul(xt,1-a) + torch.mul(torch.tanh(z),a*g)\n",
    "\n",
    "def predict_yGPU(wout,xu):\n",
    "    return torch.matmul(wout, xu)\n",
    "\n",
    "def get_matrixGPU(n,r,sr):\n",
    "    A = (torch.rand((n,n),dtype=dtype,\n",
    "                   device=torch.device(DEVICE))-.5)*r\n",
    "    At = torch.transpose(A,0,1)\n",
    "    D = torch.diag(torch.diag(A))   \n",
    "    W = A + At - D\n",
    "    eig = torch.eig(W, eigenvectors=False)\n",
    "    wsr = torch.max(torch.abs(eig[0]))\n",
    "    return W.div(wsr).mul(sr)\n",
    "\n",
    "def resize_spaces(mn, mx, best, isAlpha=False):\n",
    "    #pdb.set_trace()\n",
    "    if(best.size==0):\n",
    "        new_mn = np.max([0, mn - .5*mn])\n",
    "        new_mx = 1.5*mx\n",
    "    else:\n",
    "        best_mn = np.min(best)\n",
    "        best_mx = np.max(best)\n",
    "        mn_bound = (best_mn-mn)/2\n",
    "        mx_bound = (mx -best_mx)/2\n",
    "        new_mn, new_mx = best_mn-mn_bound, best_mx+mx_bound\n",
    "        print(f'\\nBest mn:{best_mn:.3f}\\t mn:{best_mx:.3f}')\n",
    "        print(f'New bounds mn--mx: {mn_bound:.3f}--{mx_bound:.3f}')\n",
    "    if(isAlpha):\n",
    "        if(new_mx>1):\n",
    "            new_mx = 1\n",
    "    \n",
    "    return new_mn, new_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from json import JSONEncoder\n",
    "\n",
    "# numpy arrays cannot be written to json \n",
    "# convert to list\n",
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self,obj):\n",
    "        if isinstance(obj,np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self,obj)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_a, max_a = .55, .7\n",
    "#min_sr, max_sr = .8, 1.\n",
    "#min_g, max_g = 1.4, 1.7\n",
    "#min_ri, max_ri = .001, 4.\n",
    "#min_rr, max_rr = .001, 4.\n",
    "min_a, max_a = .7, 1.\n",
    "min_sr, max_sr = 1.5, 3.\n",
    "min_g, max_g = .001, 2.\n",
    "min_ri, max_ri = .3, 3.5\n",
    "min_rr, max_rr = .4, 4.\n",
    "\n",
    "space = [Real(min_a, max_a, name='a'),\n",
    "         Real(min_sr, max_sr, name='sr'),\n",
    "         Real(min_ri, max_ri, name='ri'),\n",
    "         Real(min_rr, max_rr, name='rr')\n",
    "        ]\n",
    "\n",
    "@use_named_args(space)\n",
    "def loop(a=1.0,sr=1.0,ri=1.0,rr=1.0):\n",
    "    start = time.time()\n",
    "    amp = 1.\n",
    "    global running_error, s, counter, signal, N, ref, rn, \\\n",
    "           alphas, rhos, gammas, inScales, resScales, dict_model, \\\n",
    "           model_counter, error_per_N, error_over_N, best_N_model\n",
    "    \n",
    "    ut = torch.zeros((1,1),dtype=dtype,\n",
    "                     device=torch.device(DEVICE))\n",
    "    tp = torch.zeros((1,1),dtype=dtype,\n",
    "                     device=torch.device(DEVICE))\n",
    "    \n",
    "    Wres = get_matrixGPU(N,rr,sr)\n",
    "    Win, Wfb, Wout = get_weight_matricesGPU(K,N,L,ri,RF)\n",
    "    Wnet = torch.cat((Win,Wres,Wfb),1)\n",
    "    xt, yt = set_vectorsGPU(N,L,rr)\n",
    "\n",
    "    states = torch.zeros((TRAINLENGTH, N+K),dtype=dtype,\n",
    "                         device=DEVICE)\n",
    "    targets = torch.zeros((TRAINLENGTH),dtype=dtype, device=DEVICE)\n",
    "    for i in range(TRAINLENGTH):\n",
    "        ut[0,0] = s[i]\n",
    "        tp[0,0] = s[i+1]\n",
    "        targets[i] = s[i+1]\n",
    "        uxy = torch.cat((ut,xt,yt),0)\n",
    "        xt1 = update_res_stateGPU(Wnet,xt,uxy,a,amp)\n",
    "        xu = torch.transpose(torch.cat((xt1,ut),0),0,1).to(DEVICE)\n",
    "        states[i,:] = xu[0,:]\n",
    "        xt, yt = xt1, tp \n",
    "\n",
    "    state = states.detach().cpu().numpy()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    wout = rct.get_trained_weights(state[BURNIN:],\n",
    "                                   signal[BURNIN+1:TRAINLENGTH+1],\n",
    "                                   REG)\n",
    "    Wout = torch.from_numpy(wout.reshape(L,N+K)).type(dtype).cuda(DEVICE)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    predictions = torch.zeros((M+int(FREERUN/DT),1),\n",
    "                              dtype=dtype,\n",
    "                              device=torch.device(DEVICE))\n",
    "\n",
    "    xt, yt = set_vectorsGPU(N,L,rr)\n",
    "    ut.fill_(0.0)\n",
    "    for i in range(M+int(FREERUN/DT)):\n",
    "        if(i < TRAINLENGTH):\n",
    "            ut[0,0] = s[i]\n",
    "        else:\n",
    "            ut = yt\n",
    "        uxy = torch.cat((ut,xt,yt),0)\n",
    "        xt1 = update_res_stateGPU(Wnet,xt,uxy,a,amp)\n",
    "        xu = torch.cat((xt1,ut),0).to(DEVICE)\n",
    "        yt1 = predict_yGPU(Wout,xu)\n",
    "        predictions[i] = yt1[0,0]\n",
    "        xt, yt = xt1, yt1\n",
    "\n",
    "    yHat_GPU = predictions.detach().cpu().numpy()\n",
    "    \n",
    "    nrmse = 1000.0\n",
    "    try:\n",
    "        nrmse = rca.NRMSE(np.exp(signal[TRAINLENGTH:TRAINLENGTH+TEST]+MU_X),\n",
    "                          np.exp(yHat_GPU[TRAINLENGTH:TRAINLENGTH+TEST]+MU_X),\n",
    "                          MINMAX) \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    av = signal[TRAINLENGTH:TRAINLENGTH+TEST].reshape(TEST,1)\n",
    "    bv = np.squeeze(yHat_GPU[TRAINLENGTH:TRAINLENGTH+TEST]).reshape(TEST,1)\n",
    "    num = np.squeeze(np.dot(av.T,bv))\n",
    "    den = np.linalg.norm(av)*np.linalg.norm(bv)\n",
    "    cosine_similarity = num/den\n",
    "    cosine_distance = 1 - cosine_similarity\n",
    "    dist = cosine_distance\n",
    "    \n",
    "    loss = nrmse + dist\n",
    "    if(np.isnan(loss) or (np.isinf(loss) or (loss > 1000.0))):\n",
    "        loss = 1000\n",
    "    \n",
    "    if((loss < running_error) and (nrmse < .007)):\n",
    "        print(f'Dist {dist:3f}')\n",
    "        running_error = loss\n",
    "        wnet = Wnet.detach().cpu().numpy()\n",
    "        currentParams = np.array([a,sr,amp,ri,rr,loss])\n",
    "        if(error_over_N > running_error):\n",
    "            print('\\n\\nNew N best!!!!!!!!!!!!\\n\\n')\n",
    "            error_over_N = running_error  #set the lowest error\n",
    "            best_N_model = [N,ref,rn,counter]\n",
    "            states_dict = {'States': state}\n",
    "            with open(f'Dicts/States/states_Lz_{N}.json', 'w') as fp:\n",
    "                json.dump(states_dict, fp, cls=NumpyArrayEncoder)\n",
    "            dict_model[str(N)] = {'Wnet': wnet,\n",
    "                                  'Wout': wout,\n",
    "                                  'Preds': yHat_GPU,\n",
    "                                  'Params': currentParams}\n",
    "            print(best_N_model)\n",
    "        \n",
    "        alphas.append(a)\n",
    "        rhos.append(sr)\n",
    "        gammas.append(amp)\n",
    "        inScales.append(ri)\n",
    "        resScales.append(rr)\n",
    "        \n",
    "        fig = plt.figure(figsize=(10,8))\n",
    "        ax1 = plt.subplot(111)\n",
    "        ax1.plot(signal[TRAINLENGTH-LEAD:], label='Target')\n",
    "        ax1.plot(yHat_GPU[TRAINLENGTH-LEAD:], label='GPU')\n",
    "        ax1.axvline(LEAD,c='orange',linestyle='dashed')\n",
    "        ax1.axvline(LEAD+TEST,c='r',linestyle='dashed')\n",
    "        ax1.set_ylim(-4,4)\n",
    "        ax1.legend()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        model_counter += 1\n",
    "        error_per_N.append(nrmse)\n",
    "        \n",
    "        print(f' Iter={counter} a={a:.3f} sr={sr:.3f} amp={amp:.3f}',\n",
    "              f' ri={ri:.3f} rr={rr:.3f} loss={loss:3f} nrmse={nrmse:3f} CD {dist:3f}')\n",
    "    ####### Running info ##############################\n",
    "    print(f'Iter: {counter} #### Time {(time.time()-start):.2f}',\n",
    "          f' NRMSE {nrmse:.3f} CD {dist:.3f}')\n",
    "    ###### Store this run #############################\n",
    "    dict_counters[str(N)] = {'numModels': model_counter,\n",
    "                             'meanError': np.mean(np.array(error_per_N),axis=0).tolist(),\n",
    "                             'varError' : np.var(np.array(error_per_N),axis=0).tolist()}\n",
    "    counter += 1\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Size28 ref 0 -- Run 0 ***********\n",
      "Iter: 0 #### Time 8.09  NRMSE 0.220 CD 0.674\n",
      "Iter: 1 #### Time 3.97  NRMSE 0.225 CD 1.013\n",
      "Iter: 2 #### Time 3.97  NRMSE 1000.000 CD nan\n",
      "Iter: 3 #### Time 3.95  NRMSE 0.182 CD 0.954\n",
      "Iter: 4 #### Time 4.05  NRMSE 0.206 CD 0.980\n",
      "Iter: 5 #### Time 3.95  NRMSE 0.209 CD 0.913\n",
      "Iter: 6 #### Time 3.93  NRMSE 0.228 CD 0.984\n",
      "Iter: 7 #### Time 3.93  NRMSE 0.580 CD 1.048\n",
      "Iter: 8 #### Time 3.94  NRMSE 0.228 CD 0.919\n",
      "Iter: 9 #### Time 3.97  NRMSE 1000.000 CD nan\n",
      "Iter: 10 #### Time 3.94  NRMSE 0.200 CD 0.980\n",
      "Iter: 11 #### Time 3.94  NRMSE 1000.000 CD nan\n",
      "Iter: 12 #### Time 3.94  NRMSE 0.222 CD 0.962\n",
      "Iter: 13 #### Time 3.95  NRMSE 0.190 CD 0.958\n",
      "Iter: 14 #### Time 3.95  NRMSE 0.229 CD 0.889\n",
      "Iter: 15 #### Time 3.95  NRMSE 0.197 CD 0.956\n",
      "Iter: 16 #### Time 3.95  NRMSE 25.970 CD 0.997\n",
      "Iter: 17 #### Time 3.95  NRMSE 0.289 CD 1.327\n",
      "Iter: 18 #### Time 3.93  NRMSE 0.336 CD 1.000\n",
      "Iter: 19 #### Time 3.95  NRMSE 29194.771 CD 1.009\n",
      "Iter: 20 #### Time 3.93  NRMSE 0.232 CD 0.979\n",
      "Iter: 21 #### Time 3.94  NRMSE 0.203 CD 0.781\n",
      "Iter: 22 #### Time 3.95  NRMSE 0.191 CD 0.948\n",
      "Iter: 23 #### Time 3.95  NRMSE 1000.000 CD nan\n",
      "Iter: 24 #### Time 3.93  NRMSE 0.225 CD 0.870\n",
      "Iter: 25 #### Time 3.94  NRMSE 0.252 CD 0.976\n",
      "Iter: 26 #### Time 4.02  NRMSE 0.188 CD 0.971\n",
      "Iter: 27 #### Time 4.97  NRMSE 0.199 CD 0.980\n",
      "Iter: 28 #### Time 5.48  NRMSE 0.235 CD 1.062\n",
      "Iter: 29 #### Time 5.55  NRMSE 1000.000 CD 1.000\n",
      "Iter: 30 #### Time 5.51  NRMSE 1000.000 CD nan\n",
      "Iter: 31 #### Time 5.48  NRMSE 1000.000 CD nan\n",
      "Iter: 32 #### Time 5.58  NRMSE 1000.000 CD nan\n",
      "Iter: 33 #### Time 5.51  NRMSE 0.195 CD 0.971\n",
      "Iter: 34 #### Time 5.49  NRMSE 0.231 CD 0.993\n",
      "Iter: 35 #### Time 5.46  NRMSE 0.426 CD 0.869\n",
      "Iter: 36 #### Time 5.47  NRMSE 178435279.210 CD 0.980\n",
      "Iter: 37 #### Time 5.54  NRMSE 1000.000 CD 0.993\n",
      "Iter: 38 #### Time 5.47  NRMSE 1000.000 CD nan\n",
      "Iter: 39 #### Time 5.61  NRMSE 0.179 CD 0.895\n",
      "Iter: 40 #### Time 5.35  NRMSE 1000.000 CD nan\n",
      "Iter: 41 #### Time 4.05  NRMSE 0.223 CD 1.039\n",
      "Iter: 42 #### Time 3.96  NRMSE 0.257 CD 1.064\n",
      "Iter: 43 #### Time 3.95  NRMSE 1000.000 CD nan\n",
      "Iter: 44 #### Time 4.00  NRMSE 1000.000 CD nan\n",
      "Iter: 45 #### Time 3.96  NRMSE 1000.000 CD nan\n",
      "Iter: 46 #### Time 3.96  NRMSE 0.213 CD 1.027\n",
      "Iter: 47 #### Time 3.95  NRMSE 0.225 CD 1.025\n",
      "Iter: 48 #### Time 4.73  NRMSE 1313295112780.587 CD 0.999\n",
      "Iter: 49 #### Time 6.18  NRMSE 0.257 CD 1.133\n",
      "Iter: 50 #### Time 5.56  NRMSE 0.189 CD 0.579\n",
      "Iter: 51 #### Time 4.70  NRMSE 1000.000 CD 1.011\n",
      "Iter: 52 #### Time 4.01  NRMSE 0.238 CD 1.082\n",
      "Iter: 53 #### Time 4.01  NRMSE 0.165 CD 0.444\n",
      "Iter: 54 #### Time 3.99  NRMSE 0.470 CD 0.989\n",
      "Iter: 55 #### Time 3.97  NRMSE 0.225 CD 0.986\n",
      "Iter: 56 #### Time 3.99  NRMSE 0.216 CD 0.650\n",
      "Iter: 57 #### Time 4.03  NRMSE 1000.000 CD nan\n",
      "Iter: 58 #### Time 4.24  NRMSE 345.254 CD 1.004\n",
      "Iter: 59 #### Time 4.04  NRMSE 0.269 CD 1.132\n",
      "Iter: 60 #### Time 4.08  NRMSE 0.193 CD 0.971\n",
      "Iter: 61 #### Time 3.96  NRMSE 0.210 CD 0.957\n",
      "Iter: 62 #### Time 3.97  NRMSE 0.252 CD 0.906\n",
      "Iter: 63 #### Time 3.95  NRMSE 1000.000 CD nan\n",
      "Iter: 64 #### Time 3.99  NRMSE 1998782567.559 CD 0.992\n",
      "Iter: 65 #### Time 3.97  NRMSE 0.241 CD 1.008\n",
      "Iter: 66 #### Time 4.00  NRMSE 0.518 CD 0.991\n",
      "Iter: 67 #### Time 3.97  NRMSE 1000.000 CD nan\n",
      "Iter: 68 #### Time 3.93  NRMSE 0.190 CD 0.607\n",
      "Iter: 69 #### Time 3.96  NRMSE 0.207 CD 0.988\n",
      "Iter: 70 #### Time 3.96  NRMSE 0.193 CD 0.993\n",
      "Iter: 71 #### Time 3.98  NRMSE 1000.000 CD 0.993\n",
      "Iter: 72 #### Time 4.11  NRMSE 0.184 CD 0.939\n",
      "Iter: 73 #### Time 3.97  NRMSE 1000.000 CD 0.990\n",
      "Iter: 74 #### Time 3.94  NRMSE 0.209 CD 1.044\n",
      "Iter: 75 #### Time 3.99  NRMSE 1000.000 CD nan\n",
      "Iter: 76 #### Time 4.18  NRMSE 0.195 CD 0.861\n",
      "Iter: 77 #### Time 4.02  NRMSE 1000.000 CD nan\n",
      "Iter: 78 #### Time 4.02  NRMSE 0.269 CD 0.984\n",
      "Iter: 79 #### Time 3.97  NRMSE 0.239 CD 0.891\n",
      "Iter: 80 #### Time 3.97  NRMSE 0.185 CD 0.839\n",
      "Iter: 81 #### Time 3.95  NRMSE 1000.000 CD nan\n",
      "Iter: 82 #### Time 4.00  NRMSE 1000.000 CD nan\n",
      "Iter: 83 #### Time 4.17  NRMSE 1000.000 CD nan\n",
      "Iter: 84 #### Time 4.12  NRMSE 810948365738081920.000 CD 0.994\n",
      "Iter: 85 #### Time 4.25  NRMSE 0.225 CD 1.010\n",
      "Iter: 86 #### Time 5.04  NRMSE 0.529 CD 0.998\n",
      "Iter: 87 #### Time 5.76  NRMSE 0.327 CD 1.119\n",
      "Iter: 88 #### Time 6.01  NRMSE 1000.000 CD 1.000\n",
      "Iter: 89 #### Time 5.84  NRMSE 0.202 CD 1.083\n",
      "Iter: 90 #### Time 5.74  NRMSE 0.255 CD 1.036\n",
      "Iter: 91 #### Time 5.85  NRMSE 1000.000 CD nan\n",
      "Iter: 92 #### Time 5.34  NRMSE 0.297 CD 1.165\n",
      "Iter: 93 #### Time 4.10  NRMSE 0.195 CD 0.956\n",
      "Iter: 94 #### Time 4.13  NRMSE 0.204 CD 1.037\n",
      "Iter: 95 #### Time 4.19  NRMSE 0.206 CD 1.008\n",
      "Iter: 96 #### Time 3.95  NRMSE 0.199 CD 0.996\n",
      "Iter: 97 #### Time 4.35  NRMSE 1000.000 CD nan\n",
      "Iter: 98 #### Time 4.20  NRMSE 1000.000 CD nan\n",
      "Iter: 99 #### Time 4.05  NRMSE 1000.000 CD nan\n",
      "End Run 0 Time 445.514\n",
      "\n",
      "Best result = 0.6088302345387772\n",
      "a = 0.717417698121854\n",
      "sr = 2.357103911480357\n",
      "amp = 1.1087302900037013\n",
      "ri = 1.906011050640001\n",
      "********** Size28 ref 0 -- Run 1 ***********\n",
      "Iter: 0 #### Time 4.15  NRMSE 0.159 CD 0.527\n",
      "Iter: 1 #### Time 4.08  NRMSE 0.245 CD 0.962\n",
      "Iter: 2 #### Time 4.16  NRMSE 1000.000 CD nan\n",
      "Iter: 3 #### Time 4.17  NRMSE 0.242 CD 1.096\n",
      "Iter: 4 #### Time 4.03  NRMSE 1.584 CD 0.928\n",
      "Iter: 5 #### Time 4.19  NRMSE 1000.000 CD nan\n",
      "Iter: 6 #### Time 4.25  NRMSE 0.225 CD 0.983\n",
      "Iter: 7 #### Time 4.09  NRMSE 0.225 CD 0.878\n",
      "Iter: 8 #### Time 4.22  NRMSE 0.224 CD 0.877\n",
      "Iter: 9 #### Time 4.13  NRMSE 0.579 CD 0.896\n",
      "Iter: 10 #### Time 4.06  NRMSE 43.258 CD 0.990\n",
      "Iter: 11 #### Time 4.15  NRMSE 0.205 CD 0.963\n",
      "Iter: 12 #### Time 4.16  NRMSE 1000.000 CD nan\n"
     ]
    }
   ],
   "source": [
    "CALLS = 100\n",
    "s = torch.torch.from_numpy(signal).cuda(DEVICE).type(dtype)\n",
    "# Skipped 1000\n",
    "#size = [300,50,40,30,20,10]\n",
    "size = [28,26,24,22,20,18,16,14,12]\n",
    "rand_state = [11,37,3,24,91]\n",
    "\n",
    "dict_counters = {}\n",
    "dict_model = {}\n",
    "for N in size:\n",
    "    model_counter = 0\n",
    "    error_per_N = []\n",
    "    best_N_model = [N,0,0,0]\n",
    "    \n",
    "    min_a, max_a = .7, 1.\n",
    "    min_sr, max_sr = 1.5, 3.\n",
    "    min_g, max_g = .001, 2.\n",
    "    min_ri, max_ri = .3, 3.5\n",
    "    min_rr, max_rr = .4, 4.\n",
    "    space = [Real(min_a, max_a, name='a'),\n",
    "             Real(min_sr, max_sr, name='sr'),\n",
    "             Real(min_ri, max_ri, name='ri'),\n",
    "             Real(min_rr, max_rr, name='rr')\n",
    "            ]\n",
    "    error_over_N = 1000\n",
    "    for ref in range(5):\n",
    "        \n",
    "        alphas = []\n",
    "        rhos = []\n",
    "        gammas = []\n",
    "        inScales = []\n",
    "        resScales = []\n",
    "        \n",
    "        for rn in range(5):\n",
    "            start = time.time()\n",
    "            running_error = 1000\n",
    "            counter = 0 \n",
    "            print(f'********** Size{N} ref {ref} -- Run {rn} ***********')\n",
    "            result_gp = gp_minimize(loop,\n",
    "                                    space,\n",
    "                                    n_calls=CALLS,\n",
    "                                    random_state=rand_state[rn],\n",
    "                                    n_jobs=4,\n",
    "                                    n_initial_points=100)\n",
    "            end = time.time()-start\n",
    "            print(f'End Run {rn} Time {end:.3f}')\n",
    "            print(f'\\nBest result = {result_gp.fun}')\n",
    "            names = ['a','sr','amp','ri','rr']\n",
    "            for i in range(len(space)):\n",
    "                print(f'{names[i]} = {result_gp.x[i]}')\n",
    "            \n",
    "        min_a, max_a   = resize_spaces(min_a, max_a,\n",
    "                                       np.array(alphas),\n",
    "                                       isAlpha=True)\n",
    "        min_sr, max_sr = resize_spaces(min_sr, max_sr, np.array(rhos))\n",
    "        min_g, max_g   = resize_spaces(min_g, max_g, np.array(gammas))\n",
    "        min_ri, max_ri = resize_spaces(min_ri, max_ri, np.array(inScales))\n",
    "        min_rr, max_rr = resize_spaces(min_rr, max_rr, np.array(resScales))\n",
    "        print('Refined search bounds:\\n')\n",
    "        print(f'Alpha ({min_a}, {max_a})\\n')\n",
    "        print(f'Rho ({min_sr}, {max_sr})\\n')\n",
    "        print(f'Gamma ({min_g}, {max_g})\\n')\n",
    "        print(f'r-in ({min_ri}, {max_ri})\\n')\n",
    "        print(f'r-res ({min_rr}, {max_rr})\\n')\n",
    "        \n",
    "        \n",
    "    print(f'Overall best model {best_N_model}')\n",
    "    dict_counters[str(N)] = {'numModels': model_counter,\n",
    "                             'meanError': np.mean(np.array(error_per_N)).tolist(),\n",
    "                             'varError' : np.var(np.array(error_per_N)).tolist()}\n",
    "with open('Dicts/diag_Lz_sm.json', 'w') as fp:\n",
    "    json.dump(dict_counters, fp, cls=NumpyArrayEncoder)\n",
    "with open('Dicts/models_Lz_sm.json', 'w') as fp:\n",
    "    json.dump(dict_model, fp, cls=NumpyArrayEncoder)\n",
    "print(dict_counters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 24\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"text.usetex\"] = True \n",
    "plt.rcParams[\"axes.xmargin\"] = 0 \n",
    "plt.rcParams[\"axes.titlesize\"] = fontsize \n",
    "plt.rcParams[\"axes.labelsize\"] = fontsize\n",
    "plt.rcParams[\"xtick.labelsize\"] = fontsize\n",
    "plt.rcParams[\"ytick.labelsize\"] = fontsize\n",
    "plt.rcParams[\"axes.labelsize\"] = fontsize\n",
    "plt.rcParams[\"font.weight\"] = \"heavy\"\n",
    "plt.rcParams[\"axes.labelweight\"] = \"heavy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = 'Dicts/diag_Lz.json'\n",
    "with open(fpath,'r') as j:\n",
    "    dict_diag = json.loads(j.read())\n",
    "\n",
    "fpath = 'Dicts/models_Lz.json'\n",
    "with open(fpath,'r') as j:\n",
    "    dict_models = json.loads(j.read())\n",
    "\n",
    "size = [300,50,40,30, 20,10]\n",
    "plt.plot(signal[TRAINLENGTH:TRAINLENGTH + TEST], color='g', label='target')\n",
    "for n in size:\n",
    "    preds = dict_models[str(n)]['Preds']\n",
    "    error_testset = rca.NRMSE(signal[TRAINLENGTH:TRAINLENGTH + TEST],\n",
    "                              preds[TRAINLENGTH:TRAINLENGTH + TEST],\n",
    "                              MINMAX)\n",
    "    kl,_,_,_ = rca.distribution(signal[TRAINLENGTH:TRAINLENGTH + TEST],\n",
    "                                preds[TRAINLENGTH:TRAINLENGTH + TEST],\n",
    "                                 np.min(signal[:TRAINLENGTH+TEST]),\n",
    "                                 np.max(signal[:TRAINLENGTH+TEST]),\n",
    "                                 bins=50)\n",
    "    print(f'N={n}   Error = {error_testset:3f} Div = {kl:.3f}')\n",
    "    plt.plot(preds[TRAINLENGTH:TRAINLENGTH + TEST],\n",
    "             linestyle='dotted', label=f'preds{n}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fsolve\n",
    "def rank_curve(cplus, tols):\n",
    "    rank_tols = []\n",
    "    for i in tols:\n",
    "        rank_tols.append(rca.rank(cplus, i))\n",
    "    return np.array(rank_tols)\n",
    "\n",
    "K = 1\n",
    "L = 1\n",
    "tols = [1/10**x for x in range(0,30)]\n",
    "plt.figure()\n",
    "for n in size:\n",
    "    mat = np.array(dict_models[str(n)]['Wnet'])\n",
    "    Wr, Wi = rca.get_mats(None, K,n, matrix=mat)\n",
    "    # params [alpha, spectralradius, gamma, ri, rr, loss]\n",
    "    p = dict_models[str(n)]['Params']\n",
    "    a,g = p[0], p[2]\n",
    "    print(f'Alpha {a} --- Gamma {g}')\n",
    "    x0 = np.zeros((n,1))\n",
    "    u0 = np.zeros((K,1))\n",
    "    A = rca.leaky_jacobian(x0, u0, a, g, Wi, Wr)\n",
    "    B = rca.partial_u(x0, u0, a, g, Wi, Wr)\n",
    "    rhoA = np.max(np.abs(rca.eig_spectrum(A)))\n",
    "    Cn = np.nan_to_num(rca.reachable_matrix(A,B))\n",
    "    if(K != 3): # Square Cn\n",
    "        Cn = Cn/np.max(np.abs(rca.eig_spectrum(Cn)))\n",
    "    else:            # Non-square Cn\n",
    "        Cn = Cn/np.max(np.abs(np.linalg.svd(Cn, compute_uv=False)))\n",
    "\n",
    "    rkc = rank_curve(Cn, tols)\n",
    "    v = np.argmax(np.gradient(rkc))\n",
    "    plt.plot(rkc, label=f'N={n}')\n",
    "    plt.vlines([v],0,50)\n",
    "    ave_rank = (rkc[v]+rkc[v+1])//2\n",
    "    print(f'Ave rank for N={n} is {ave_rank} Tolerance {tols[v]} Rho A {rhoA.round(3)}')\n",
    "plt.ylim(0,50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rxy(x,y):\n",
    "    return np.dot(x.T,y)/(np.linalg.norm(x)*np.linalg.norm(y))\n",
    "\n",
    "thresh = []\n",
    "start = TRAINLENGTH - 1000\n",
    "stop = M+FREERUN\n",
    "k_list = [28]\n",
    "plt.figure(figsize=(15,5))\n",
    "for k in k_list:\n",
    "    lengthTC = (stop-start)-k\n",
    "    trainCorr = np.zeros(lengthTC) # 21000-k\n",
    "    pred = np.array(dict_models[str(k)]['Preds'])\n",
    "    for j in range(start,stop-k):\n",
    "        tar = signal[j:j+k].reshape((k,1))\n",
    "        prd = pred[j:j+k].reshape((k,1))\n",
    "        trainCorr[j-start] = Rxy(tar,prd)\n",
    "    minVal = trainCorr[:1000].min()\n",
    "    threshold = minVal*.95\n",
    "    thresholdLoc = np.where(trainCorr[1000:]<threshold)[0][0]\n",
    "    thresh.append(thresholdLoc)\n",
    "    print(f'k-size={k} Trainingset min={minVal.round(3)}  threshold={threshold:.3f}',\n",
    "          f' Location={thresholdLoc}')\n",
    "    plt.plot(trainCorr[500:2000], color='r', label=f'k={k}')\n",
    "plt.plot(signal[TRAINLENGTH-500:TRAINLENGTH+TEST], color='k', label='target')\n",
    "plt.plot(pred[TRAINLENGTH-500:TRAINLENGTH+TEST],color='b', label='pred')\n",
    "plt.axvline(500+thresholdLoc,color='r')\n",
    "plt.axvline(500,color='r',linestyle='dashed')\n",
    "plt.ylabel('$\\mathbf{R}_{xy}$')\n",
    "plt.xlabel('Time-steps $t$')\n",
    "plt.legend(fontsize=24,loc='lower left')\n",
    "plt.title('Prediction divergence (red lines) by $\\mathbf{R}_{xy}[k]$ for $k=30$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaos plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "def rank_along_trajectory(wr, wi, a, g, forcing, n, k, tolerance, delX):\n",
    "    T = forcing.shape[0]\n",
    "    ranks = np.zeros(T)\n",
    "    conds = np.zeros(T)\n",
    "    radii = np.zeros(T)\n",
    "    uncertainty = np.zeros((n,T))\n",
    "    def Func(x):\n",
    "        return np.squeeze(-x.reshape(n,1) + (1-a)*x.reshape(n,1) +\\\n",
    "                          a*g*np.tanh(np.dot(wr,x.reshape(n,1)) +\\\n",
    "                         (np.dot(wi,ueq.reshape(k,1)).reshape(n,1))))\n",
    "    for i in range(T):\n",
    "        ueq = forcing[i]\n",
    "        x0 = np.ones((n,1))*.5\n",
    "        xeq = (fsolve(Func,x0)).reshape(n,1)\n",
    "        A = rca.leaky_jacobian(xeq, ueq.reshape(k,1), a, g, Wi, Wr)\n",
    "        radii[i] = np.max(np.abs(rca.eig_spectrum(A)))\n",
    "        conds[i] = rca.condition_number(A)[0]\n",
    "        B = rca.partial_u(xeq, ueq.reshape(k,1), a, g, Wi, Wr)\n",
    "        uncertainty[:,i] = np.squeeze(np.dot(A,delX))\n",
    "        Cplus = rca.controllability_matrix(A, B)\n",
    "        ranks[i] = rca.rank(Cplus, tolerance)\n",
    "        print(f'Time-step: {i} Rank: {ranks[i]} Uncertainty: {np.linalg.norm(uncertainty):.2f}  CondNum: {conds[i]:.2f}')\n",
    "    return ranks, uncertainty, conds, radii\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n=30\n",
    "pred = np.array(dict_models[str(n)]['Preds'])\n",
    "data_dict = {'y': signal[14000:],\n",
    "             'yh': np.squeeze(pred[14000:]),\n",
    "            }\n",
    "alpha = .5\n",
    "bins = 50\n",
    "df = pd.DataFrame(data=data_dict)\n",
    "fig= plt.figure(figsize=(10,14))\n",
    "ax1 = plt.subplot(211)\n",
    "sns.distplot(df['y'],\n",
    "             label='$MG$',\n",
    "             bins=bins,\n",
    "             color='k',\n",
    "             axlabel=False,\n",
    "             norm_hist=True,\n",
    "             hist_kws=dict(alpha=alpha))\n",
    "sns.distplot(df['yh'],\n",
    "             label='$\\widehat{\\mathbf{y}},\\,N=30$',\n",
    "             bins=bins,\n",
    "             color='b',\n",
    "             axlabel=False,\n",
    "             norm_hist=True,\n",
    "             hist_kws=dict(alpha=alpha))\n",
    "plt.legend(loc='upper left', fontsize=fontsize)\n",
    "plt.ylabel(r'${P}(u_t)$', fontsize=26,  color='black', weight='heavy')\n",
    "plt.xlabel(r'Range of $u_t$', fontsize=26,  color='black', weight='heavy')\n",
    "plt.xticks(c='black', fontsize=fontsize)\n",
    "plt.yticks(c='black', fontsize=fontsize)\n",
    "ax1.text(-0.2, 1.,s='$(\\mathbf{a})$', transform=ax1.transAxes, \n",
    "            size=30, weight='bold')\n",
    "\n",
    "ax2 = plt.subplot(212)\n",
    "plt.rcParams['xtick.major.pad']='8'\n",
    "ax2.text(-0.2, 1.,s='$(\\mathbf{b})$', transform=ax2.transAxes, \n",
    "            size=30, weight='bold')\n",
    "ax2.plot(signal[TRAINLENGTH-100:TRAINLENGTH+TEST],'k', label=r'$MG$')\n",
    "ax2.plot(pred[TRAINLENGTH-100:TRAINLENGTH+TEST],'b-', label='$\\widehat{\\mathbf{y}},\\,N=30$')\n",
    "ax2.axvline(100, c='k',ls='dashed' )\n",
    "ax2.axvline(100+thresholdLoc, c='r',ls='dashed' )\n",
    "ax2.legend(loc='lower right',fontsize=20)\n",
    "ax2.set_xticks([0,100,200,300,400])\n",
    "ax2.set_xticklabels([-100,0,100,200,300])\n",
    "ax2.set_xlabel('Test Data Time-steps '+'($t$)', fontsize=26, color='black', weight='heavy')\n",
    "ax2.set_ylabel(r'${u_{t+1} - \\mu}$', fontsize=26, color='black', weight='heavy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
