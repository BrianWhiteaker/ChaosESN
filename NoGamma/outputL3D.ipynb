{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "##### SET TO PATH ON LOCAL SYSTEM\n",
    "sys.path.insert(1,'/home/bwhiteak/ChaosESN/ESN_utils/')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import rc_tools as rct\n",
    "import rc_analysis as rca\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "import pdb\n",
    "\n",
    "from skopt.space import Real,Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "\n",
    "from scipy.integrate import odeint\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "#jtplot.style(theme='solarizedd', context='notebook', ticks=True, grid=False)\n",
    "torch.set_num_threads(4)\n",
    "np.random.seed(11)\n",
    "torch.set_printoptions(precision=10)\n",
    "dtype = torch.float32 \n",
    "\n",
    "print(f'Python: {sys.version}')\n",
    "print(f'Numpy: {np.__version__}')\n",
    "print(f'Torch: {torch.__version__}')\n",
    "\n",
    "DEVICE = 'cuda:6'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREERUN = 20  # Extra predicition time-steps after test data\n",
    "deltaT = .02      # Number of extra free-running steps  int(20/.02) \n",
    "\n",
    "rho = 28.0\n",
    "sigma = 10.0\n",
    "beta = 8/3\n",
    "\n",
    "# Lorenz 1963\n",
    "def f(state, t):\n",
    "    x,y,z = state\n",
    "    return sigma*(y-x), x*(rho-z)-y, x*y - beta*z\n",
    "\n",
    "state0 = [1.,1.,1.]             # Initial point\n",
    "t = np.arange(0,300+FREERUN,deltaT)  # Total of 320 full steps with deltaT=.02\n",
    "states = odeint(f,state0,t)\n",
    "\n",
    "mu = np.mean(states, axis=0)       # Get mean for each of x,y,z\n",
    "signal = (states - mu)[:,[0,1,2]]  # Mean center the data\n",
    "M = signal.shape[0] - int(FREERUN/deltaT)  # Length of train plus test... no freerun\n",
    "K = 3                                  # Input dimension\n",
    "L = 3                                  # Output dimension\n",
    "RF = .5                                # For feedback <--- not implemented\n",
    "TEST = 1000                            # length of test\n",
    "LEAD = 100                            # Number of points to plot before test\n",
    "BURNIN = 100                           # Number of steps ignored for random x0 to fade\n",
    "REG = 1e-8                             # Regularization factor for ridge regression\n",
    "TRAINLENGTH = M-TEST    \n",
    "\n",
    "MINMAXS = np.max(signal[:TRAINLENGTH+TEST],axis=0)-np.min(signal[:TRAINLENGTH+TEST],axis=0)\n",
    "STD = np.std(signal[:TRAINLENGTH+TEST],axis=0)\n",
    "RGS = [(-19.5,19.5),(-27,27),(-25,25)]\n",
    "BINS = 50\n",
    "\n",
    "print(f'Signal length M={M}')\n",
    "print(f'Normalizing value MM is {MINMAXS}')\n",
    "print(f'std = {STD}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions and plotting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_matricesGPU(k,n,l,ri,ro):\n",
    "    win = torch.rand((n,k),dtype=dtype,\n",
    "                      device=torch.device(DEVICE)).sub(.5).mul(ri)\n",
    "    wfb = torch.zeros((n,l),dtype=dtype, device=torch.device(DEVICE))\n",
    "    wout = torch.rand((l,n+k),dtype=dtype,\n",
    "                      device=torch.device(DEVICE)).sub(.5).mul(ro)\n",
    "    return win, wfb, wout\n",
    "\n",
    "def set_vectorsGPU(n,l,r):\n",
    "    x0 = torch.rand((n,1),dtype=dtype,\n",
    "                      device=torch.device(DEVICE)).sub(.5).mul(r)\n",
    "    y0 = torch.zeros((l,1),dtype=dtype, device=torch.device(DEVICE))\n",
    "    return x0, y0\n",
    "\n",
    "def update_res_stateGPU(wnet,xt,uxy,a,g):\n",
    "    z = torch.matmul(wnet,uxy)\n",
    "    return torch.mul(xt,1-a) + torch.mul(torch.tanh(z),a*g)\n",
    "\n",
    "def predict_yGPU(wout,xu):\n",
    "    return torch.matmul(wout, xu)\n",
    "\n",
    "def get_matrixGPU(n,r,sr):\n",
    "    A = (torch.rand((n,n),dtype=dtype,\n",
    "                   device=torch.device(DEVICE))-.5)*r\n",
    "    At = torch.transpose(A,0,1)\n",
    "    D = torch.diag(torch.diag(A))   \n",
    "    W = A + At - D\n",
    "    eig = torch.eig(W, eigenvectors=False)\n",
    "    wsr = torch.max(torch.abs(eig[0]))\n",
    "    return W.div(wsr).mul(sr)\n",
    "\n",
    "def resize_spaces(mn, mx, best, isAlpha=False):\n",
    "    #pdb.set_trace()\n",
    "    if(best.size==0):\n",
    "        new_mn = np.max([0, mn - .5*mn])\n",
    "        new_mx = 1.5*mx\n",
    "    else:\n",
    "        best_mn = np.min(best)\n",
    "        best_mx = np.max(best)\n",
    "        mn_bound = (best_mn-mn)/2\n",
    "        mx_bound = (mx -best_mx)/2\n",
    "        new_mn, new_mx = best_mn-mn_bound, best_mx+mx_bound\n",
    "        print(f'\\nBest mn:{best_mn:.3f}\\t mn:{best_mx:.3f}')\n",
    "        print(f'New bounds mn--mx: {mn_bound:.3f}--{mx_bound:.3f}')\n",
    "    if(isAlpha):\n",
    "        if(new_mx>1):\n",
    "            new_mx = 1\n",
    "    \n",
    "    return new_mn, new_mx\n",
    "\n",
    "import json\n",
    "from json import JSONEncoder\n",
    "\n",
    "# numpy arrays cannot be written to json \n",
    "# convert to list\n",
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self,obj):\n",
    "        if isinstance(obj,np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self,obj)\n",
    "    \n",
    "\n",
    "\n",
    "fontsize = 24\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"text.usetex\"] = True \n",
    "plt.rcParams[\"axes.xmargin\"] = 0 \n",
    "plt.rcParams[\"axes.titlesize\"] = fontsize \n",
    "plt.rcParams[\"axes.labelsize\"] = fontsize\n",
    "plt.rcParams[\"xtick.labelsize\"] = fontsize\n",
    "plt.rcParams[\"ytick.labelsize\"] = fontsize\n",
    "plt.rcParams[\"axes.labelsize\"] = fontsize\n",
    "plt.rcParams[\"font.weight\"] = \"heavy\"\n",
    "plt.rcParams[\"axes.labelweight\"] = \"heavy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and saving dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('Dicts/diagL3D.json', 'w') as fp:\n",
    "#    json.dump(dict_diag, fp, cls=NumpyArrayEncoder)\n",
    "#with open('Dicts/modelsL3D.json', 'w') as fp:\n",
    "#    json.dump(dict_models, fp, cls=NumpyArrayEncoder)\n",
    "\n",
    "fpath = 'Dicts0/diagL3D.json'\n",
    "with open(fpath,'r') as j:\n",
    "    dict_diag = json.loads(j.read())\n",
    "\n",
    "fpath = 'Dicts0/modelsL3D.json'\n",
    "with open(fpath,'r') as j:\n",
    "    dict_models = json.loads(j.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot low-error model counts by size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = [1000, 800, 600, 400, 300, 200, 100,\n",
    "        50, 40, 30, 28, 26, 24, 22, 20, 18, 16, 14, 12,10]\n",
    "\n",
    "mean_errors = []\n",
    "num_models = []\n",
    "for i in size:\n",
    "    try:\n",
    "        err = np.max(dict_diag[str(i)]['meanError'])\n",
    "    except:\n",
    "        err = 0\n",
    "    if(np.isnan(err)):\n",
    "        err=0\n",
    "    mean_errors.append(err)\n",
    "    \n",
    "    try:\n",
    "        num = dict_diag[str(i)]['numModels']\n",
    "    except:\n",
    "        num = 0\n",
    "    if(np.isnan(err)):\n",
    "        num = 0\n",
    "    num_models.append(num)\n",
    "np.save('num_modelsL3D_2',num_models)\n",
    "\n",
    "plt.scatter(size[::-1],num_models[::-1])\n",
    "plt.xlabel('Size $N$')\n",
    "plt.ylabel('Number of Models')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('mean_errorL3D_2', mean_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D plots of target with prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "variable = ['X','Y','Z']\n",
    "\n",
    "Nplots = len(size)\n",
    "\n",
    "for n in range(Nplots):\n",
    "    try:\n",
    "        count  = dict_diag[str(size[n])]['numModels']\n",
    "    except:\n",
    "        count = 0\n",
    "    if((count == 0) or (count == None)):\n",
    "        continue\n",
    "    preds = np.array(dict_models[str(size[n])]['Preds'])\n",
    "    fig, ax = plt.subplots(3, figsize=(10,8), sharex=True)\n",
    "    for sp in range(3):\n",
    "        ax[sp].set_title(f'{variable[sp]} Predictions')\n",
    "\n",
    "        error_testset = rca.NRMSE(signal[TRAINLENGTH:TRAINLENGTH + TEST,sp],\n",
    "                              preds[TRAINLENGTH:TRAINLENGTH + TEST,sp],\n",
    "                              MINMAXS[sp])\n",
    "        kl,_,_,_ = rca.distribution(signal[TRAINLENGTH:TRAINLENGTH + TEST,sp],\n",
    "                                    preds[TRAINLENGTH:TRAINLENGTH + TEST,sp],\n",
    "                                     np.min(signal[:TRAINLENGTH+TEST,sp]),\n",
    "                                     np.max(signal[:TRAINLENGTH+TEST,sp]),\n",
    "                                     bins=50)\n",
    "        ekl = error_testset*kl\n",
    "        print(f' N={size[n]} Dim={sp}  Error = {error_testset.round(2)} KL-div = {np.round(kl,2)} ekl = {np.round(kl,2)}')\n",
    "        ax[sp].plot(signal[TRAINLENGTH:TRAINLENGTH + TEST,sp], color='k',label='target', alpha=0)\n",
    "        if(sp==2):\n",
    "            ax[sp].plot(signal[TRAINLENGTH:TRAINLENGTH + TEST,sp], color='k')\n",
    "            ax[sp].plot(preds[TRAINLENGTH:TRAINLENGTH + TEST,sp], label=f'N={size[n]}')\n",
    "        else:\n",
    "            ax[sp].plot(signal[TRAINLENGTH:TRAINLENGTH + TEST,sp], color='k')\n",
    "            ax[sp].plot(preds[TRAINLENGTH:TRAINLENGTH + TEST,sp])\n",
    "    plt.legend(bbox_to_anchor=(1.11, 2.05))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Rank Method-1 for all sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tols = [1/10**x for x in range(5,20)]\n",
    "\n",
    "from scipy.optimize import fsolve\n",
    "def rank_curve(cplus, tols):\n",
    "    rank_tols = []\n",
    "    for i in tols:\n",
    "        rank_tols.append(rca.rank(cplus, i))\n",
    "    return np.array(rank_tols)\n",
    "#def test():\n",
    "all_ranks = []\n",
    "K = 3\n",
    "L = 3\n",
    "tols = [1/10**x for x in range(5,20)]\n",
    "plt.figure()\n",
    "for n in size:\n",
    "    #pdb.set_trace()\n",
    "    n = str(n)\n",
    "    try:\n",
    "        count  = dict_diag[n]['numModels']\n",
    "    except KeyError:\n",
    "        count = 0\n",
    "    \n",
    "    if(not count):\n",
    "        all_ranks.append(0)\n",
    "        continue\n",
    "\n",
    "    mat = np.array(dict_models[n]['Wnet'])\n",
    "    Wr, Wi = rca.get_mats(None, K,int(n), matrix=mat)\n",
    "    # params [alpha, spectralradius, gamma, ri, rr, loss]\n",
    "    p = dict_models[str(n)]['Params']\n",
    "    a,g = p[0], p[2]\n",
    "    sr = p[1]\n",
    "    \n",
    "    x0 = np.zeros((int(n),1))\n",
    "    u0 = np.zeros((K,1))\n",
    "    A = rca.leaky_jacobian(x0, u0, a, g, Wi, Wr)\n",
    "    B = rca.partial_u(x0, u0, a, g, Wi, Wr)\n",
    "    rhoA = np.max(np.abs(rca.eig_spectrum(A)))\n",
    "    Cn = np.nan_to_num(rca.reachable_matrix(A,B))\n",
    "    if(K != 3): # Square Cn\n",
    "        Cn = Cn/np.max(np.abs(rca.eig_spectrum(Cn)))\n",
    "    else:            # Non-square Cn\n",
    "        Cn = Cn/np.max(np.abs(np.linalg.svd(Cn, compute_uv=False)))\n",
    "\n",
    "    rkc = rank_curve(Cn, tols)\n",
    "    v = np.argmax(np.gradient(rkc))\n",
    "    plt.plot(rkc, label=f'N={n}')\n",
    "    plt.vlines([v],0,50, color='k')\n",
    "    ave_rank = (rkc[v]+rkc[v+1])//2\n",
    "    print(f'Targeted reduced rank for N={n} is {ave_rank}\\nValue v= {v} Tolerance {tols[v]} Rho A {rhoA.round(2)}')\n",
    "    print(f'Alpha {np.round(a,2)} --- Rho {np.round(sr,2)}\\n')\n",
    "    all_ranks.append(ave_rank)\n",
    "plt.title('Rank vs Tolerance for various size $N$')\n",
    "plt.xlabel('Tolerance $\\epsilon > 10^{-x}$')\n",
    "plt.ylabel('$\\mathrm{rank(C_{N};\\epsilon)}$')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim(0,50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('ranksL3D_2',all_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-Log Plot Rank Method-1 vs Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(size[::-1],all_ranks[::-1], label='indicated')\n",
    "plt.loglog(size[::-1],size[::-1], label='N')\n",
    "plt.xlabel('Size $N$')\n",
    "plt.ylabel('$\\mathrm{rank}(C_N)$')\n",
    "plt.grid(True, which=\"both\", ls=\"-\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.gridspec as gridspec\n",
    "from scipy.signal import argrelmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N = 30\n",
    "K = 3\n",
    "v = 0\n",
    "pred = np.array(dict_models[str(N)]['Preds'])\n",
    "start, end= 13900,15000\n",
    "p = dict_models[str(N)]['Params']\n",
    "mat = np.array(dict_models[str(N)]['Wnet'])\n",
    "Wr, Wi = rca.get_mats(None, K,N, matrix=mat)\n",
    "sig_rks,radii = rca.rank_along_trajectory( Wr, Wi, p[0], p[2],\n",
    "                            signal[start:end], N, K, tols[v])\n",
    "pred_rks,_ = rca.rank_along_trajectory( Wr, Wi, p[0], p[2],\n",
    "                            pred[start:end],N, K, tols[v])\n",
    "\n",
    "top,bottom  = 13900,15000\n",
    "mu = np.array([.56018255, .55704211, 23.59124571])\n",
    "\n",
    "gs = gridspec.GridSpec(2, 1, hspace=.01)\n",
    "fig = plt.figure(figsize=(12,24))\n",
    "ax1 = fig.add_subplot(gs[0], projection='3d')\n",
    "ax1.plot(signal[14000:,0]+mu[0],\n",
    "         signal[14000:,1]+mu[1],\n",
    "         signal[14000:,2]+mu[2],\n",
    "         c='k', label='$L3D$')\n",
    "ax1.plot(pred[14000:,0]+mu[0],\n",
    "         pred[14000:,1]+mu[1],\n",
    "         pred[14000:,2]+mu[2],\n",
    "         c='r', label='$\\widehat{\\mathbf{y}},\\enspace N=30$', alpha=.5)\n",
    "ax1.set_xlabel('$v^{(1)}_t$', fontsize=26, color='black')\n",
    "ax1.set_ylabel('$v^{(2)}_t$', fontsize=26, color='black')\n",
    "ax1.set_zlabel('$v^{(3)}_t$', fontsize=26, color='black')\n",
    "ax1.w_xaxis.set_pane_color ((0., 0., 0., 0.))\n",
    "ax1.w_yaxis.set_pane_color ((0., 0., 0., 0.))\n",
    "ax1.w_zaxis.set_pane_color ((0., 0., 0., 0.))\n",
    "ax1.xaxis.labelpad = 20\n",
    "ax1.yaxis.labelpad = 20\n",
    "ax1.zaxis.labelpad = 20\n",
    "ax1.set_zticklabels([10,20,30,40])\n",
    "ax1.legend(fontsize=24,\n",
    "           labelcolor='black',\n",
    "           ncol=2,\n",
    "           handlelength=.5,\n",
    "           borderpad=.2,\n",
    "           borderaxespad=.2)\n",
    "ax1.text(-.2, 1.,310,s='$(\\mathbf{a})$', transform=ax1.transAxes, \n",
    "            size=30, weight='bold')\n",
    "\n",
    "gs1 = gs[1].subgridspec(2,1, hspace=.02)\n",
    "ax2 = plt.subplot(gs1[0])\n",
    "ax2.text(-0.2, 1.,s='$(\\mathbf{b})$', transform=ax2.transAxes, \n",
    "            size=30, weight='bold')\n",
    "ax2.plot([x for x in range(top,bottom-500)],signal[top:bottom-500, 0], color='k', label='$v^{(1)}_t$')\n",
    "#ax2.plot([x for x in range(top,bottom-500)],signal[top:bottom-500, 2], color='m',\n",
    "#          linestyle='solid', alpha=.7, label='$v^{(3)}_t$')\n",
    "ax2.plot([x for x in range(top,bottom-500)],pred[top:bottom-500, 0],'r', ms=3, label = '$\\widehat{y}^{(1)},\\enspace N=30$')\n",
    "ax2.axvline(top+100, color='k', linestyle='dashed')\n",
    "ax2.axvline(top+100+412, color='r', linestyle='dashed')\n",
    "ax2.set_ylabel('$v^{(1)} -\\mu_{v^{(1)}}$', labelpad=10)\n",
    "ax2.set_ylim(-25,25)\n",
    "ax2.legend(loc='upper right',\n",
    "           ncol=3 ,\n",
    "           handlelength=.5,\n",
    "           fontsize=22,\n",
    "           borderpad=.2,\n",
    "           borderaxespad=.2)\n",
    "ax2.set_xticks([])\n",
    "lowlim, uplim =17,28\n",
    "ax3 = plt.subplot(gs1[1])\n",
    "ax3.plot([x for x in range(top,bottom-500)],\n",
    "         sig_rks[:-500].astype(int), color='k',\n",
    "         label='$L3D$', alpha=.8)\n",
    "ax3.plot([x for x in range(top,bottom-500)],\n",
    "         pred_rks[:-500].astype(int), color= 'r',\n",
    "         label='$\\widehat{\\mathbf{y}},$ $N=30$', alpha=.6)\n",
    "\n",
    "ax3.set_ylabel('$\\mathrm{rank}(\\mathbf{\\mathcal{C}}_{30})$', labelpad=22)\n",
    "ax3.set_xlabel('Time-step $t$')\n",
    "ax3.text(-0.2, 0,s='$(\\mathbf{c})$', transform=ax2.transAxes, \n",
    "            size=30, weight='bold')\n",
    "ax3.legend(handlelength=.5,\n",
    "           ncol=2,\n",
    "           loc='lower right',\n",
    "           fontsize=22,\n",
    "           borderpad=.2,\n",
    "           borderaxespad=.2)\n",
    "ax3.set_xticks([13900,14000,14100,14200,14300,14400])\n",
    "ax3.set_xticklabels([-100,0,100,200,300,400])\n",
    "ax3.set_yticks([20,25])\n",
    "ax3.set_yticklabels([20,25])\n",
    "ax2.vlines(np.where(radii[:-500]>1.3)[0]+13900 , -25,25, color='k', linewidths=1, alpha=.15)\n",
    "ax3.vlines(np.where(radii[:-500]>1.3)[0]+13900 , lowlim,uplim, color='k', linewidths=1, alpha=.15)\n",
    "ax3.axvline(top +100, color='k', linestyle='dashed')\n",
    "ax3.axvline(top +100+412, color='r', linestyle='dashed')\n",
    "ax3.set_ylim(lowlim,uplim)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"Submission/Fig4.png\", format='png',dpi=300, bbox_inches='tight', pad_inches=.01)\n",
    "fig.savefig(\"Submission/Fig4.pdf\", format='pdf',dpi=300, bbox_inches='tight', pad_inches=.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get time-step of divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_mats = []\n",
    "threshs = []\n",
    "locs = []\n",
    "\n",
    "def Rxy(x,y):\n",
    "    return np.dot(x.T,y)/(np.linalg.norm(x)*np.linalg.norm(y))\n",
    "\n",
    "FREE =1000\n",
    "T = M + FREE\n",
    "DIMS = K\n",
    "Nplots = len(size)\n",
    "for i in range(Nplots):\n",
    "    correlations = np.zeros((DIMS,T))\n",
    "    thresholds = np.zeros(DIMS)\n",
    "    threshold_location = np.zeros(DIMS, dtype=int)\n",
    "    k = size[i]\n",
    "    try:\n",
    "        count  = dict_diag[str(size[i])]['numModels']\n",
    "    except:\n",
    "        count = 0\n",
    "    if(count == 0):\n",
    "        continue\n",
    "    for i in range(DIMS):\n",
    "        corr_length = T-k # calculate for j= 0,..., M-k\n",
    "        pred = np.array(dict_models[str(size[i])]['Preds']) # Get size N predictions\n",
    "\n",
    "        for j in range(corr_length):\n",
    "            tar = signal[j:j+k,i].reshape((k,1))\n",
    "            prd = pred[j:j+k,i].reshape((k,1))\n",
    "            correlations[i,j] = Rxy(tar,prd)\n",
    "\n",
    "        minVal = correlations[i,TRAINLENGTH-1000:TRAINLENGTH].min()\n",
    "        thresholds[i] = minVal*.95\n",
    "        threshold_location[i] = np.where(correlations[i,TRAINLENGTH:]<thresholds[i])[0][0]\n",
    "        print(f'k-size={k} Trainingset min={minVal.round(3)}  threshold={thresholds[i]:.3f}',\n",
    "              f' Location={threshold_location[i]}')\n",
    "    print('\\n')\n",
    "    div_mats.append(correlations)\n",
    "    threshs.append(thresholds)\n",
    "    locs.append(threshold_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = TRAINLENGTH - 1000\n",
    "stop = M+FREERUN\n",
    "\n",
    "Nplots = len(div_mats)\n",
    "\n",
    "for n in range(Nplots):\n",
    "    try:\n",
    "        count  = dict_diag[str(size[n])]['numModels']\n",
    "    except:\n",
    "        count = 0\n",
    "    if(count == 0):\n",
    "        continue\n",
    "    fig, ax = plt.subplots(3, figsize=(10,9))\n",
    "    print(f'N={size[n]}')\n",
    "    trainCorr = div_mats[n]\n",
    "    thresholdLoc = locs[n]\n",
    "    for sp in range(3):\n",
    "        mx = np.max(np.abs(signal[:TRAINLENGTH,sp]))\n",
    "        print(f'N {size[n]} corr {trainCorr.shape}')\n",
    "        ax[sp].plot(div_mats[n][sp,TRAINLENGTH:TRAINLENGTH+TEST], color='r', label=f'k={k}')\n",
    "        ax[sp].plot(signal[TRAINLENGTH:TRAINLENGTH+TEST,sp]/mx, color='k', label='target')\n",
    "        ax[sp].plot(pred[TRAINLENGTH:TRAINLENGTH+TEST,sp]/mx, label='pred')\n",
    "        ax[sp].axvline(thresholdLoc[sp],color='r',\n",
    "                       linestyle='dashed',label='diverged')\n",
    "        ax[sp].axhline(threshs[n][sp],linestyle='dotted',color='r')\n",
    "        #ax[sp].axvline(500,color='k',linestyle='dashed')\n",
    "        ax[sp].set_ylabel('$\\mathbf{R}_{xy}$')\n",
    "        ax[sp].set_xlabel('Time-steps $t$ samples are: Train $[0,1000]$, Test $[1000,1500]$')\n",
    "        #ax[sp].set_xticklabels([-500,-250,0,250,500,750])\n",
    "        plt.legend(fontsize=24,bbox_to_anchor=(1.31, 2.05))\n",
    "        ax[0].set_title('Correlation (solid red) at $t$-step (dashed red), $\\mathbf{R}_{xy}[k]<\\mathrm{threshold}$ (dotted red) ')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
